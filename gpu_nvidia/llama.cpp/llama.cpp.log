INFO:    Starting build...
INFO:    Fetching OCI image...
INFO:    Extracting OCI image...
2025/03/27 21:59:19  warn rootless{usr/local/nvm/versions/node/v16.20.2/bin/corepack} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:20  warn rootless{usr/local/nvm/versions/node/v16.20.2/bin/npm} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:20  warn rootless{usr/local/nvm/versions/node/v16.20.2/bin/npx} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:47  warn rootless{usr/bin/protoc} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_bad_any_cast_impl.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_bad_optional_access.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_bad_variant_access.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_base.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_city.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_civil_time.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_cord.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_cord_internal.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_cordz_functions.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_cordz_handle.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_cordz_info.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_cordz_sample_token.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_crc32c.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_crc_cord_state.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_crc_cpu_detect.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_crc_internal.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_debugging_internal.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_demangle_internal.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_die_if_null.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_examine_stack.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_exponential_biased.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_failure_signal_handler.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_flags.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_flags_commandlineflag.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_flags_commandlineflag_internal.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_flags_config.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_flags_internal.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_flags_marshalling.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_flags_parse.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_flags_private_handle_accessor.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_flags_program_name.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_flags_reflection.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_flags_usage.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_flags_usage_internal.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_graphcycles_internal.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_hash.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_hashtablez_sampler.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_int128.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_kernel_timeout_internal.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_leak_check.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_log_entry.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_log_flags.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_log_globals.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_log_initialize.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_log_internal_check_op.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_log_internal_conditions.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_log_internal_format.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_log_internal_globals.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_log_internal_log_sink_set.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_log_internal_message.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_log_internal_nullguard.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_log_internal_proto.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_log_severity.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_log_sink.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_low_level_hash.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_malloc_internal.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_periodic_sampler.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_random_distributions.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_random_internal_distribution_test_util.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_random_internal_platform.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_random_internal_pool_urbg.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_random_internal_randen.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_random_internal_randen_hwaes.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_random_internal_randen_hwaes_impl.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_random_internal_randen_slow.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_random_internal_seed_material.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_random_seed_gen_exception.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_random_seed_sequences.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_raw_hash_set.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_raw_logging_internal.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_scoped_set_env.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_spinlock_wait.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_stacktrace.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_status.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_statusor.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_str_format_internal.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_strerror.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_string_view.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_strings.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_strings_internal.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_symbolize.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_synchronization.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_throw_delegate.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_time.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libabsl_time_zone.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libaddress_sorting.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libaddress_sorting.so.39} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libarrow.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libarrow.so.1400} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libarrow_acero.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libarrow_acero.so.1400} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libarrow_dataset.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:48  warn rootless{usr/lib/libarrow_dataset.so.1400} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libfmt.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libfmt.so.10} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgpr.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgpr.so.39} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc++.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc++.so.1.62} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc++_alts.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc++_alts.so.1.62} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc++_error_details.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc++_error_details.so.1.62} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc++_reflection.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc++_reflection.so.1.62} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc++_unsecure.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc++_unsecure.so.1.62} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc.so.39} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc_authorization_provider.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc_authorization_provider.so.1.62} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc_plugin_support.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc_plugin_support.so.1.62} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc_unsecure.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpc_unsecure.so.39} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpcpp_channelz.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libgrpcpp_channelz.so.1.62} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libparquet.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libparquet.so.1400} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libprotobuf-lite.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libprotobuf.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:50  warn rootless{usr/lib/libprotoc.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:51  warn rootless{usr/lib/libspdlog.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:51  warn rootless{usr/lib/libspdlog.so.1.12} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:51  warn rootless{usr/lib/libupb_base_lib.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:51  warn rootless{usr/lib/libupb_base_lib.so.39} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:51  warn rootless{usr/lib/libupb_json_lib.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:51  warn rootless{usr/lib/libupb_json_lib.so.39} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:51  warn rootless{usr/lib/libupb_mem_lib.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:51  warn rootless{usr/lib/libupb_mem_lib.so.39} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:51  warn rootless{usr/lib/libupb_message_lib.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:51  warn rootless{usr/lib/libupb_message_lib.so.39} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:51  warn rootless{usr/lib/libupb_textformat_lib.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:51  warn rootless{usr/lib/libupb_textformat_lib.so.39} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:51  warn rootless{usr/lib/libutf8_range_lib.so} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
2025/03/27 21:59:51  warn rootless{usr/lib/libutf8_range_lib.so.39} ignoring (usually) harmless EPERM on setxattr "user.rootlesscontainers"
INFO:    Inserting Singularity configuration...
INFO:    Running setup scriptlet
+ mkdir /tmp/build-temp-3833667637/rootfs/lvs0
INFO:    Running post scriptlet
+ apt-get update
Get:1 http://ports.ubuntu.com/ubuntu-ports jammy InRelease [270 kB]
Get:2 http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease [128 kB]
Get:3 http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease [127 kB]
Get:4 http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease [129 kB]
Get:5 http://ports.ubuntu.com/ubuntu-ports jammy/universe arm64 Packages [17.2 MB]
Get:6 http://ports.ubuntu.com/ubuntu-ports jammy/restricted arm64 Packages [24.2 kB]
Get:7 http://ports.ubuntu.com/ubuntu-ports jammy/main arm64 Packages [1758 kB]
Get:8 http://ports.ubuntu.com/ubuntu-ports jammy/multiverse arm64 Packages [224 kB]
Get:9 http://ports.ubuntu.com/ubuntu-ports jammy-updates/restricted arm64 Packages [3333 kB]
Get:10 http://ports.ubuntu.com/ubuntu-ports jammy-updates/universe arm64 Packages [1499 kB]
Get:11 http://ports.ubuntu.com/ubuntu-ports jammy-updates/multiverse arm64 Packages [32.8 kB]
Get:12 http://ports.ubuntu.com/ubuntu-ports jammy-updates/main arm64 Packages [2708 kB]
Get:13 http://ports.ubuntu.com/ubuntu-ports jammy-backports/universe arm64 Packages [33.2 kB]
Get:14 http://ports.ubuntu.com/ubuntu-ports jammy-backports/main arm64 Packages [82.3 kB]
Get:15 http://ports.ubuntu.com/ubuntu-ports jammy-security/multiverse arm64 Packages [26.5 kB]
Get:16 http://ports.ubuntu.com/ubuntu-ports jammy-security/universe arm64 Packages [1205 kB]
Get:17 http://ports.ubuntu.com/ubuntu-ports jammy-security/main arm64 Packages [2405 kB]
Get:18 http://ports.ubuntu.com/ubuntu-ports jammy-security/restricted arm64 Packages [3180 kB]
Fetched 34.4 MB in 10s (3500 kB/s)
Reading package lists...
+ apt-get install -y --no-install-recommends wget vim build-essential libcurl4-openssl-dev
Reading package lists...
Building dependency tree...
Reading state information...
build-essential is already the newest version (12.9ubuntu3).
The following additional packages will be installed:
  curl libcurl4 vim-common vim-runtime
Suggested packages:
  libcurl4-doc libidn11-dev libkrb5-dev libldap2-dev librtmp-dev libssh2-1-dev
  ctags vim-doc vim-scripts
The following packages will be upgraded:
  curl libcurl4 libcurl4-openssl-dev vim vim-common vim-runtime wget
7 upgraded, 0 newly installed, 0 to remove and 60 not upgraded.
Need to get 9780 kB of archives.
After this operation, 52.2 kB disk space will be freed.
Get:1 http://ports.ubuntu.com/ubuntu-ports jammy-updates/main arm64 vim arm64 2:8.2.3995-1ubuntu2.23 [1664 kB]
Get:2 http://ports.ubuntu.com/ubuntu-ports jammy-updates/main arm64 vim-runtime all 2:8.2.3995-1ubuntu2.23 [6833 kB]
Get:3 http://ports.ubuntu.com/ubuntu-ports jammy-updates/main arm64 vim-common all 2:8.2.3995-1ubuntu2.23 [81.5 kB]
Get:4 http://ports.ubuntu.com/ubuntu-ports jammy-updates/main arm64 wget arm64 1.21.2-2ubuntu1.1 [334 kB]
Get:5 http://ports.ubuntu.com/ubuntu-ports jammy-updates/main arm64 libcurl4-openssl-dev arm64 7.81.0-1ubuntu1.20 [392 kB]
Get:6 http://ports.ubuntu.com/ubuntu-ports jammy-updates/main arm64 curl arm64 7.81.0-1ubuntu1.20 [190 kB]
Get:7 http://ports.ubuntu.com/ubuntu-ports jammy-updates/main arm64 libcurl4 arm64 7.81.0-1ubuntu1.20 [284 kB]
debconf: unable to initialize frontend: Dialog
debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 7.)
debconf: falling back to frontend: Readline
Fetched 9780 kB in 4s (2281 kB/s)
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 22738 files and directories currently installed.)
Preparing to unpack .../0-vim_2%3a8.2.3995-1ubuntu2.23_arm64.deb ...
Unpacking vim (2:8.2.3995-1ubuntu2.23) over (2:8.2.3995-1ubuntu2.16) ...
Preparing to unpack .../1-vim-runtime_2%3a8.2.3995-1ubuntu2.23_all.deb ...
Unpacking vim-runtime (2:8.2.3995-1ubuntu2.23) over (2:8.2.3995-1ubuntu2.16) ...
Preparing to unpack .../2-vim-common_2%3a8.2.3995-1ubuntu2.23_all.deb ...
Unpacking vim-common (2:8.2.3995-1ubuntu2.23) over (2:8.2.3995-1ubuntu2.16) ...
Preparing to unpack .../3-wget_1.21.2-2ubuntu1.1_arm64.deb ...
Unpacking wget (1.21.2-2ubuntu1.1) over (1.21.2-2ubuntu1) ...
Preparing to unpack .../4-libcurl4-openssl-dev_7.81.0-1ubuntu1.20_arm64.deb ...
Unpacking libcurl4-openssl-dev:arm64 (7.81.0-1ubuntu1.20) over (7.81.0-1ubuntu1.16) ...
Preparing to unpack .../5-curl_7.81.0-1ubuntu1.20_arm64.deb ...
Unpacking curl (7.81.0-1ubuntu1.20) over (7.81.0-1ubuntu1.16) ...
Preparing to unpack .../6-libcurl4_7.81.0-1ubuntu1.20_arm64.deb ...
Unpacking libcurl4:arm64 (7.81.0-1ubuntu1.20) over (7.81.0-1ubuntu1.16) ...
Setting up wget (1.21.2-2ubuntu1.1) ...
Setting up vim-common (2:8.2.3995-1ubuntu2.23) ...
Setting up libcurl4:arm64 (7.81.0-1ubuntu1.20) ...
Setting up curl (7.81.0-1ubuntu1.20) ...
Setting up vim-runtime (2:8.2.3995-1ubuntu2.23) ...
Setting up vim (2:8.2.3995-1ubuntu2.23) ...
Setting up libcurl4-openssl-dev:arm64 (7.81.0-1ubuntu1.20) ...
Processing triggers for libc-bin (2.35-0ubuntu3.6) ...
+ apt-get clean
+ rm -rf /var/lib/apt/lists/auxfiles /var/lib/apt/lists/lock /var/lib/apt/lists/partial /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy-backports_InRelease /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy-backports_main_binary-arm64_Packages.lz4 /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy-backports_universe_binary-arm64_Packages.lz4 /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy-security_InRelease /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy-security_main_binary-arm64_Packages.lz4 /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy-security_multiverse_binary-arm64_Packages.lz4 /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy-security_restricted_binary-arm64_Packages.lz4 /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy-security_universe_binary-arm64_Packages.lz4 /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy-updates_InRelease /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy-updates_main_binary-arm64_Packages.lz4 /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy-updates_multiverse_binary-arm64_Packages.lz4 /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy-updates_restricted_binary-arm64_Packages.lz4 /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy-updates_universe_binary-arm64_Packages.lz4 /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy_InRelease /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy_main_binary-arm64_Packages.lz4 /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy_multiverse_binary-arm64_Packages.lz4 /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy_restricted_binary-arm64_Packages.lz4 /var/lib/apt/lists/ports.ubuntu.com_ubuntu-ports_dists_jammy_universe_binary-arm64_Packages.lz4
+ mkdir /opt/uv
+ export UV_INSTALL_DIR=/opt/uv
+ curl -LsSf https://astral.sh/uv/install.sh
+ sh
downloading uv 0.6.10 aarch64-unknown-linux-gnu
no checksums to verify
installing to /opt/uv
  uv
  uvx
everything's installed!

To add /opt/uv to your PATH, either restart your shell or run:

    source /opt/uv/env (sh, bash, zsh)
    source /opt/uv/env.fish (fish)
WARNING: The following commands are shadowed by other commands in your PATH: uv uvx
+ cd /opt
+ git clone https://github.com/ggerganov/llama.cpp.git
Cloning into 'llama.cpp'...
+ cd llama.cpp
+ git checkout b4953
Note: switching to 'b4953'.

You are in 'detached HEAD' state. You can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by switching back to a branch.

If you want to create a new branch to retain commits you create, you may
do so (now or later) by using -c with the switch command. Example:

  git switch -c <new-branch-name>

Or undo this operation with:

  git switch -

Turn off this advice by setting config variable advice.detachedHead to false

HEAD is now at 2d77d88e context : fix worst-case reserve outputs (#12545)
+ cmake -B build -DGGML_CUDA=ON -DGGML_CUDA_ENABLE_UNIFIED_MEMORY=1 -DGGML_CUDA_FORCE_CUBLAS=true -DGGML_CUDA_F16=true -DLLAMA_CURL=ON
-- The C compiler identification is GNU 11.4.0
-- The CXX compiler identification is GNU 11.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found Git: /usr/bin/git (found version "2.34.1")
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE
-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF
-- CMAKE_SYSTEM_PROCESSOR: aarch64
-- Including CPU backend
-- Found OpenMP_C: -fopenmp (found version "4.5")
-- Found OpenMP_CXX: -fopenmp (found version "4.5")
-- Found OpenMP: TRUE (found version "4.5")
-- ARM detected
-- Performing Test GGML_COMPILER_SUPPORTS_FP16_FORMAT_I3E
-- Performing Test GGML_COMPILER_SUPPORTS_FP16_FORMAT_I3E - Failed
-- Performing Test GGML_MACHINE_SUPPORTS_dotprod
-- Performing Test GGML_MACHINE_SUPPORTS_dotprod - Success
-- Performing Test GGML_MACHINE_SUPPORTS_i8mm
-- Performing Test GGML_MACHINE_SUPPORTS_i8mm - Success
-- Performing Test GGML_MACHINE_SUPPORTS_sve
-- Performing Test GGML_MACHINE_SUPPORTS_sve - Success
-- Performing Test GGML_MACHINE_SUPPORTS_sme
-- Performing Test GGML_MACHINE_SUPPORTS_sme - Failed
-- Performing Test GGML_MACHINE_SUPPORTS_nosme
-- Performing Test GGML_MACHINE_SUPPORTS_nosme - Failed
-- ARM feature DOTPROD enabled
-- ARM feature SVE enabled
-- ARM feature MATMUL_INT8 enabled
-- ARM feature FMA enabled
-- ARM feature FP16_VECTOR_ARITHMETIC enabled
-- Adding CPU backend variant ggml-cpu: -mcpu=neoverse-v2+crypto+sve2-sm4+sve2-aes+sve2-sha3+norng+nomemtag+nopredres+nopauth+dotprod+i8mm+sve 
-- Found CUDAToolkit: /usr/local/cuda/targets/sbsa-linux/include (found version "12.4.131")
-- CUDA Toolkit found
-- Using CUDA architectures: native
-- The CUDA compiler identification is NVIDIA 12.4.131
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
-- CUDA host compiler is GNU 11.4.0

-- Including CUDA backend
-- Found CURL: /usr/lib/aarch64-linux-gnu/libcurl.so (found version "7.81.0")
-- Configuring done (7.9s)
-- Generating done (0.1s)
-- Build files have been written to: /opt/llama.cpp/build
+ cd build
+ cmake --build . --verbose -j32
Change Dir: '/opt/llama.cpp/build'

/usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -S/opt/llama.cpp -B/opt/llama.cpp/build --check-build-system CMakeFiles/Makefile.cmake 0
/usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_progress_start /opt/llama.cpp/build/CMakeFiles /opt/llama.cpp/build//CMakeFiles/progress.marks
/usr/bin/gmake  -f CMakeFiles/Makefile2 all
gmake[1]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f ggml/src/CMakeFiles/ggml-base.dir/build.make ggml/src/CMakeFiles/ggml-base.dir/depend
/usr/bin/gmake  -f common/CMakeFiles/build_info.dir/build.make common/CMakeFiles/build_info.dir/depend
/usr/bin/gmake  -f examples/gguf-hash/CMakeFiles/sha256.dir/build.make examples/gguf-hash/CMakeFiles/sha256.dir/depend
/usr/bin/gmake  -f examples/gguf-hash/CMakeFiles/xxhash.dir/build.make examples/gguf-hash/CMakeFiles/xxhash.dir/depend
/usr/bin/gmake  -f examples/gguf-hash/CMakeFiles/sha1.dir/build.make examples/gguf-hash/CMakeFiles/sha1.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/ggml/src /opt/llama.cpp/build /opt/llama.cpp/build/ggml/src /opt/llama.cpp/build/ggml/src/CMakeFiles/ggml-base.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/gguf-hash /opt/llama.cpp/build /opt/llama.cpp/build/examples/gguf-hash /opt/llama.cpp/build/examples/gguf-hash/CMakeFiles/sha256.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/gguf-hash /opt/llama.cpp/build /opt/llama.cpp/build/examples/gguf-hash /opt/llama.cpp/build/examples/gguf-hash/CMakeFiles/xxhash.dir/DependInfo.cmake "--color="
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/gguf-hash /opt/llama.cpp/build /opt/llama.cpp/build/examples/gguf-hash /opt/llama.cpp/build/examples/gguf-hash/CMakeFiles/sha1.dir/DependInfo.cmake "--color="
[  0%] Generating build details from Git
cd /opt/llama.cpp && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -DMSVC= -DCMAKE_C_COMPILER_VERSION=11.4.0 -DCMAKE_C_COMPILER_ID=GNU -DCMAKE_VS_PLATFORM_NAME= -DCMAKE_C_COMPILER=/usr/bin/cc -P /opt/llama.cpp/common/cmake/build-info-gen-cpp.cmake
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f ggml/src/CMakeFiles/ggml-base.dir/build.make ggml/src/CMakeFiles/ggml-base.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/gguf-hash/CMakeFiles/sha256.dir/build.make examples/gguf-hash/CMakeFiles/sha256.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/gguf-hash/CMakeFiles/sha1.dir/build.make examples/gguf-hash/CMakeFiles/sha1.dir/build
/usr/bin/gmake  -f examples/gguf-hash/CMakeFiles/xxhash.dir/build.make examples/gguf-hash/CMakeFiles/xxhash.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
[  0%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o
[  0%] Building C object examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o
[  0%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o
cd /opt/llama.cpp/build/ggml/src && /usr/bin/cc -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/opt/llama.cpp/ggml/src/. -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -MD -MT ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o -MF CMakeFiles/ggml-base.dir/ggml.c.o.d -o CMakeFiles/ggml-base.dir/ggml.c.o -c /opt/llama.cpp/ggml/src/ggml.c
cd /opt/llama.cpp/build/examples/gguf-hash && /usr/bin/cc  -I/opt/llama.cpp/examples -I/opt/llama.cpp/examples/gguf-hash/deps -O3 -DNDEBUG -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -MD -MT examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o -MF CMakeFiles/sha256.dir/deps/sha256/sha256.c.o.d -o CMakeFiles/sha256.dir/deps/sha256/sha256.c.o -c /opt/llama.cpp/examples/gguf-hash/deps/sha256/sha256.c
cd /opt/llama.cpp/build/ggml/src && /usr/bin/cc -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/opt/llama.cpp/ggml/src/. -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -MD -MT ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o -MF CMakeFiles/ggml-base.dir/ggml-alloc.c.o.d -o CMakeFiles/ggml-base.dir/ggml-alloc.c.o -c /opt/llama.cpp/ggml/src/ggml-alloc.c
[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o
[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o
[  1%] Building C object examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o
cd /opt/llama.cpp/build/ggml/src && /usr/bin/c++ -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/opt/llama.cpp/ggml/src/. -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o -MF CMakeFiles/ggml-base.dir/ggml-opt.cpp.o.d -o CMakeFiles/ggml-base.dir/ggml-opt.cpp.o -c /opt/llama.cpp/ggml/src/ggml-opt.cpp
cd /opt/llama.cpp/build/examples/gguf-hash && /usr/bin/cc  -I/opt/llama.cpp/examples -I/opt/llama.cpp/examples/gguf-hash/deps -O3 -DNDEBUG -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -w -MD -MT examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o -MF CMakeFiles/sha1.dir/deps/sha1/sha1.c.o.d -o CMakeFiles/sha1.dir/deps/sha1/sha1.c.o -c /opt/llama.cpp/examples/gguf-hash/deps/sha1/sha1.c
cd /opt/llama.cpp/build/ggml/src && /usr/bin/c++ -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/opt/llama.cpp/ggml/src/. -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o -MF CMakeFiles/ggml-base.dir/ggml-backend.cpp.o.d -o CMakeFiles/ggml-base.dir/ggml-backend.cpp.o -c /opt/llama.cpp/ggml/src/ggml-backend.cpp
[  3%] Building C object examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o
-- Found Git: /usr/bin/git (found version "2.34.1")
[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o
[  3%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o
[  3%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o
cd /opt/llama.cpp/build/examples/gguf-hash && /usr/bin/cc  -I/opt/llama.cpp/examples -I/opt/llama.cpp/examples/gguf-hash/deps -O3 -DNDEBUG -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -MD -MT examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o -MF CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o.d -o CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o -c /opt/llama.cpp/examples/gguf-hash/deps/xxhash/xxhash.c
cd /opt/llama.cpp/build/ggml/src && /usr/bin/c++ -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/opt/llama.cpp/ggml/src/. -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o -MF CMakeFiles/ggml-base.dir/ggml-threading.cpp.o.d -o CMakeFiles/ggml-base.dir/ggml-threading.cpp.o -c /opt/llama.cpp/ggml/src/ggml-threading.cpp
cd /opt/llama.cpp/build/ggml/src && /usr/bin/cc -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/opt/llama.cpp/ggml/src/. -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -MD -MT ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o -MF CMakeFiles/ggml-base.dir/ggml-quants.c.o.d -o CMakeFiles/ggml-base.dir/ggml-quants.c.o -c /opt/llama.cpp/ggml/src/ggml-quants.c
cd /opt/llama.cpp/build/ggml/src && /usr/bin/c++ -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/opt/llama.cpp/ggml/src/. -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o -MF CMakeFiles/ggml-base.dir/gguf.cpp.o.d -o CMakeFiles/ggml-base.dir/gguf.cpp.o -c /opt/llama.cpp/ggml/src/gguf.cpp
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/common /opt/llama.cpp/build /opt/llama.cpp/build/common /opt/llama.cpp/build/common/CMakeFiles/build_info.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f common/CMakeFiles/build_info.dir/build.make common/CMakeFiles/build_info.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[  3%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o
cd /opt/llama.cpp/build/common && /usr/bin/c++   -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT common/CMakeFiles/build_info.dir/build-info.cpp.o -MF CMakeFiles/build_info.dir/build-info.cpp.o.d -o CMakeFiles/build_info.dir/build-info.cpp.o -c /opt/llama.cpp/common/build-info.cpp
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[  3%] Built target build_info
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[  3%] Built target sha1
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[  3%] Built target sha256
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[  3%] Built target xxhash
[  3%] Linking CXX shared library ../../bin/libggml-base.so
cd /opt/llama.cpp/build/ggml/src && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/ggml-base.dir/link.txt --verbose=1
/usr/bin/c++ -fPIC -O3 -DNDEBUG -shared -Wl,-soname,libggml-base.so -o ../../bin/libggml-base.so "CMakeFiles/ggml-base.dir/ggml.c.o" "CMakeFiles/ggml-base.dir/ggml-alloc.c.o" "CMakeFiles/ggml-base.dir/ggml-backend.cpp.o" "CMakeFiles/ggml-base.dir/ggml-opt.cpp.o" "CMakeFiles/ggml-base.dir/ggml-threading.cpp.o" "CMakeFiles/ggml-base.dir/ggml-quants.c.o" "CMakeFiles/ggml-base.dir/gguf.cpp.o"  -lm
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[  3%] Built target ggml-base
/usr/bin/gmake  -f ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/depend
/usr/bin/gmake  -f ggml/src/CMakeFiles/ggml-cpu.dir/build.make ggml/src/CMakeFiles/ggml-cpu.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/ggml/src /opt/llama.cpp/build /opt/llama.cpp/build/ggml/src /opt/llama.cpp/build/ggml/src/CMakeFiles/ggml-cpu.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/ggml/src/ggml-cuda /opt/llama.cpp/build /opt/llama.cpp/build/ggml/src/ggml-cuda /opt/llama.cpp/build/ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f ggml/src/CMakeFiles/ggml-cpu.dir/build.make ggml/src/CMakeFiles/ggml-cpu.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build.make ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[  4%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o
[  4%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o
cd /opt/llama.cpp/build/ggml/src && /usr/bin/cc -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_AARCH64 -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/opt/llama.cpp/ggml/src/.. -I/opt/llama.cpp/ggml/src/. -I/opt/llama.cpp/ggml/src/ggml-cpu -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -mcpu=neoverse-v2+crypto+sve2-sm4+sve2-aes+sve2-sha3+norng+nomemtag+nopredres+nopauth+dotprod+i8mm+sve -fopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o -c /opt/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.c
[  4%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o
cd /opt/llama.cpp/build/ggml/src && /usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_AARCH64 -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/opt/llama.cpp/ggml/src/.. -I/opt/llama.cpp/ggml/src/. -I/opt/llama.cpp/ggml/src/ggml-cpu -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -mcpu=neoverse-v2+crypto+sve2-sm4+sve2-aes+sve2-sha3+norng+nomemtag+nopredres+nopauth+dotprod+i8mm+sve -fopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o -c /opt/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.cpp
[  5%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o
cd /opt/llama.cpp/build/ggml/src && /usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_AARCH64 -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/opt/llama.cpp/ggml/src/.. -I/opt/llama.cpp/ggml/src/. -I/opt/llama.cpp/ggml/src/ggml-cpu -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -mcpu=neoverse-v2+crypto+sve2-sm4+sve2-aes+sve2-sha3+norng+nomemtag+nopredres+nopauth+dotprod+i8mm+sve -fopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o -c /opt/llama.cpp/ggml/src/ggml-cpu/ggml-cpu-aarch64.cpp
[  5%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o
cd /opt/llama.cpp/build/ggml/src && /usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_AARCH64 -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/opt/llama.cpp/ggml/src/.. -I/opt/llama.cpp/ggml/src/. -I/opt/llama.cpp/ggml/src/ggml-cpu -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -mcpu=neoverse-v2+crypto+sve2-sm4+sve2-aes+sve2-sha3+norng+nomemtag+nopredres+nopauth+dotprod+i8mm+sve -fopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o -c /opt/llama.cpp/ggml/src/ggml-cpu/ggml-cpu-hbm.cpp
[  5%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o
cd /opt/llama.cpp/build/ggml/src && /usr/bin/cc -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_AARCH64 -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/opt/llama.cpp/ggml/src/.. -I/opt/llama.cpp/ggml/src/. -I/opt/llama.cpp/ggml/src/ggml-cpu -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -mcpu=neoverse-v2+crypto+sve2-sm4+sve2-aes+sve2-sha3+norng+nomemtag+nopredres+nopauth+dotprod+i8mm+sve -fopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o -c /opt/llama.cpp/ggml/src/ggml-cpu/ggml-cpu-quants.c
[  6%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o
[  6%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o
cd /opt/llama.cpp/build/ggml/src && /usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_AARCH64 -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/opt/llama.cpp/ggml/src/.. -I/opt/llama.cpp/ggml/src/. -I/opt/llama.cpp/ggml/src/ggml-cpu -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -mcpu=neoverse-v2+crypto+sve2-sm4+sve2-aes+sve2-sha3+norng+nomemtag+nopredres+nopauth+dotprod+i8mm+sve -fopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o -c /opt/llama.cpp/ggml/src/ggml-cpu/ggml-cpu-traits.cpp
[  6%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o
cd /opt/llama.cpp/build/ggml/src && /usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_AARCH64 -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/opt/llama.cpp/ggml/src/.. -I/opt/llama.cpp/ggml/src/. -I/opt/llama.cpp/ggml/src/ggml-cpu -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -mcpu=neoverse-v2+crypto+sve2-sm4+sve2-aes+sve2-sha3+norng+nomemtag+nopredres+nopauth+dotprod+i8mm+sve -fopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o -c /opt/llama.cpp/ggml/src/ggml-cpu/amx/amx.cpp
cd /opt/llama.cpp/build/ggml/src && /usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_AARCH64 -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/opt/llama.cpp/ggml/src/.. -I/opt/llama.cpp/ggml/src/. -I/opt/llama.cpp/ggml/src/ggml-cpu -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -mcpu=neoverse-v2+crypto+sve2-sm4+sve2-aes+sve2-sha3+norng+nomemtag+nopredres+nopauth+dotprod+i8mm+sve -fopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o -c /opt/llama.cpp/ggml/src/ggml-cpu/amx/mmq.cpp
cd /opt/llama.cpp/build/ggml/src && /usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_AARCH64 -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/opt/llama.cpp/ggml/src/.. -I/opt/llama.cpp/ggml/src/. -I/opt/llama.cpp/ggml/src/ggml-cpu -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -mcpu=neoverse-v2+crypto+sve2-sm4+sve2-aes+sve2-sha3+norng+nomemtag+nopredres+nopauth+dotprod+i8mm+sve -fopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o -c /opt/llama.cpp/ggml/src/ggml-cpu/llamafile/sgemm.cpp
[  6%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o
[  6%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/arange.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o -MF CMakeFiles/ggml-cuda.dir/acc.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/acc.cu -o CMakeFiles/ggml-cuda.dir/acc.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/arange.cu.o -MF CMakeFiles/ggml-cuda.dir/arange.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/arange.cu -o CMakeFiles/ggml-cuda.dir/arange.cu.o
[  7%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argmax.cu.o
[  7%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argsort.cu.o
[  7%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/binbcast.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argmax.cu.o -MF CMakeFiles/ggml-cuda.dir/argmax.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/argmax.cu -o CMakeFiles/ggml-cuda.dir/argmax.cu.o
[  8%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/clamp.cu.o
[  8%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/concat.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argsort.cu.o -MF CMakeFiles/ggml-cuda.dir/argsort.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/argsort.cu -o CMakeFiles/ggml-cuda.dir/argsort.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/binbcast.cu.o -MF CMakeFiles/ggml-cuda.dir/binbcast.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/binbcast.cu -o CMakeFiles/ggml-cuda.dir/binbcast.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/clamp.cu.o -MF CMakeFiles/ggml-cuda.dir/clamp.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/clamp.cu -o CMakeFiles/ggml-cuda.dir/clamp.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/concat.cu.o -MF CMakeFiles/ggml-cuda.dir/concat.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/concat.cu -o CMakeFiles/ggml-cuda.dir/concat.cu.o
[  9%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/convert.cu.o
[  9%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv-transpose-1d.cu.o
[  9%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/count-equal.cu.o
[  9%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cpy.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv-transpose-1d.cu.o -MF CMakeFiles/ggml-cuda.dir/conv-transpose-1d.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/conv-transpose-1d.cu -o CMakeFiles/ggml-cuda.dir/conv-transpose-1d.cu.o
[ 10%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cross-entropy-loss.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/convert.cu.o -MF CMakeFiles/ggml-cuda.dir/convert.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/convert.cu -o CMakeFiles/ggml-cuda.dir/convert.cu.o
[ 10%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/diagmask.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/count-equal.cu.o -MF CMakeFiles/ggml-cuda.dir/count-equal.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/count-equal.cu -o CMakeFiles/ggml-cuda.dir/count-equal.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cpy.cu.o -MF CMakeFiles/ggml-cuda.dir/cpy.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/cpy.cu -o CMakeFiles/ggml-cuda.dir/cpy.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cross-entropy-loss.cu.o -MF CMakeFiles/ggml-cuda.dir/cross-entropy-loss.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/cross-entropy-loss.cu -o CMakeFiles/ggml-cuda.dir/cross-entropy-loss.cu.o
[ 10%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f16.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/diagmask.cu.o -MF CMakeFiles/ggml-cuda.dir/diagmask.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/diagmask.cu -o CMakeFiles/ggml-cuda.dir/diagmask.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f16.cu.o -MF CMakeFiles/ggml-cuda.dir/fattn-tile-f16.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/fattn-tile-f16.cu -o CMakeFiles/ggml-cuda.dir/fattn-tile-f16.cu.o
[ 11%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-wmma-f16.cu.o
[ 11%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f32.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f32.cu.o -MF CMakeFiles/ggml-cuda.dir/fattn-tile-f32.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/fattn-tile-f32.cu -o CMakeFiles/ggml-cuda.dir/fattn-tile-f32.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-wmma-f16.cu.o -MF CMakeFiles/ggml-cuda.dir/fattn-wmma-f16.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/fattn-wmma-f16.cu -o CMakeFiles/ggml-cuda.dir/fattn-wmma-f16.cu.o
[ 12%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn.cu.o
[ 12%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/getrows.cu.o
[ 12%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ggml-cuda.cu.o
[ 12%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/gla.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn.cu.o -MF CMakeFiles/ggml-cuda.dir/fattn.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/fattn.cu -o CMakeFiles/ggml-cuda.dir/fattn.cu.o
[ 13%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/im2col.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/getrows.cu.o -MF CMakeFiles/ggml-cuda.dir/getrows.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/getrows.cu -o CMakeFiles/ggml-cuda.dir/getrows.cu.o
[ 13%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmq.cu.o
[ 13%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmv.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ggml-cuda.cu.o -MF CMakeFiles/ggml-cuda.dir/ggml-cuda.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/ggml-cuda.cu -o CMakeFiles/ggml-cuda.dir/ggml-cuda.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/gla.cu.o -MF CMakeFiles/ggml-cuda.dir/gla.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/gla.cu -o CMakeFiles/ggml-cuda.dir/gla.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/im2col.cu.o -MF CMakeFiles/ggml-cuda.dir/im2col.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/im2col.cu -o CMakeFiles/ggml-cuda.dir/im2col.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmq.cu.o -MF CMakeFiles/ggml-cuda.dir/mmq.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/mmq.cu -o CMakeFiles/ggml-cuda.dir/mmq.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmv.cu.o -MF CMakeFiles/ggml-cuda.dir/mmv.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/mmv.cu -o CMakeFiles/ggml-cuda.dir/mmv.cu.o
[ 14%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvq.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvq.cu.o -MF CMakeFiles/ggml-cuda.dir/mmvq.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/mmvq.cu -o CMakeFiles/ggml-cuda.dir/mmvq.cu.o
[ 14%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/norm.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/norm.cu.o -MF CMakeFiles/ggml-cuda.dir/norm.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/norm.cu -o CMakeFiles/ggml-cuda.dir/norm.cu.o
[ 14%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-adamw.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-adamw.cu.o -MF CMakeFiles/ggml-cuda.dir/opt-step-adamw.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/opt-step-adamw.cu -o CMakeFiles/ggml-cuda.dir/opt-step-adamw.cu.o
[ 15%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/out-prod.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/out-prod.cu.o -MF CMakeFiles/ggml-cuda.dir/out-prod.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/out-prod.cu -o CMakeFiles/ggml-cuda.dir/out-prod.cu.o
[ 15%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pad.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pad.cu.o -MF CMakeFiles/ggml-cuda.dir/pad.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/pad.cu -o CMakeFiles/ggml-cuda.dir/pad.cu.o
[ 15%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pool2d.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pool2d.cu.o -MF CMakeFiles/ggml-cuda.dir/pool2d.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/pool2d.cu -o CMakeFiles/ggml-cuda.dir/pool2d.cu.o
[ 16%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/quantize.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/quantize.cu.o -MF CMakeFiles/ggml-cuda.dir/quantize.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/quantize.cu -o CMakeFiles/ggml-cuda.dir/quantize.cu.o
[ 16%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/rope.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/rope.cu.o -MF CMakeFiles/ggml-cuda.dir/rope.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/rope.cu -o CMakeFiles/ggml-cuda.dir/rope.cu.o
[ 17%] Linking CXX shared library ../../bin/libggml-cpu.so
cd /opt/llama.cpp/build/ggml/src && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/ggml-cpu.dir/link.txt --verbose=1
/usr/bin/c++ -fPIC -O3 -DNDEBUG -shared -Wl,-soname,libggml-cpu.so -o ../../bin/libggml-cpu.so "CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o"  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../bin/libggml-base.so /usr/lib/gcc/aarch64-linux-gnu/11/libgomp.so /usr/lib/aarch64-linux-gnu/libpthread.a
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 17%] Built target ggml-cpu
[ 17%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/scale.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/scale.cu.o -MF CMakeFiles/ggml-cuda.dir/scale.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/scale.cu -o CMakeFiles/ggml-cuda.dir/scale.cu.o
[ 18%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sum.cu.o
[ 18%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softmax.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sum.cu.o -MF CMakeFiles/ggml-cuda.dir/sum.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/sum.cu -o CMakeFiles/ggml-cuda.dir/sum.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softmax.cu.o -MF CMakeFiles/ggml-cuda.dir/softmax.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/softmax.cu -o CMakeFiles/ggml-cuda.dir/softmax.cu.o
[ 18%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sumrows.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sumrows.cu.o -MF CMakeFiles/ggml-cuda.dir/sumrows.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/sumrows.cu -o CMakeFiles/ggml-cuda.dir/sumrows.cu.o
[ 19%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/tsembd.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/tsembd.cu.o -MF CMakeFiles/ggml-cuda.dir/tsembd.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/tsembd.cu -o CMakeFiles/ggml-cuda.dir/tsembd.cu.o
[ 19%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/unary.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/unary.cu.o -MF CMakeFiles/ggml-cuda.dir/unary.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/unary.cu -o CMakeFiles/ggml-cuda.dir/unary.cu.o
[ 19%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/upscale.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/upscale.cu.o -MF CMakeFiles/ggml-cuda.dir/upscale.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/upscale.cu -o CMakeFiles/ggml-cuda.dir/upscale.cu.o
[ 20%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/wkv.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/wkv.cu.o -MF CMakeFiles/ggml-cuda.dir/wkv.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/wkv.cu -o CMakeFiles/ggml-cuda.dir/wkv.cu.o
[ 20%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu.o
[ 21%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu.o
[ 21%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu.o
[ 21%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu.o
[ 22%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu.o
[ 22%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu.o
[ 22%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu.o
[ 23%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu.o
[ 23%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu.o
[ 23%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu.o
[ 24%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu.o
[ 24%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu.o
[ 24%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu.o
[ 25%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu.o
[ 25%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu.o
[ 25%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu.o
[ 26%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq1_s.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq1_s.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq1_s.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq1_s.cu.o
[ 26%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_s.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_s.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_s.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_s.cu.o
[ 26%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xs.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xs.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xs.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xs.cu.o
[ 27%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xxs.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xxs.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xxs.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xxs.cu.o
[ 27%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_s.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_s.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_s.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_s.cu.o
[ 27%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_xxs.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_xxs.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_xxs.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_xxs.cu.o
[ 28%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_nl.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_nl.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_nl.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_nl.cu.o
[ 28%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_xs.cu.o
[ 28%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q2_k.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_xs.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_xs.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_xs.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q2_k.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q2_k.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q2_k.cu.o
[ 29%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q3_k.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q3_k.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q3_k.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q3_k.cu.o
[ 29%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_0.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_0.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_0.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_0.cu.o
[ 29%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_1.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_1.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_1.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_1.cu.o
[ 30%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_k.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_k.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_k.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_k.cu.o
[ 30%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_0.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_0.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_0.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_0.cu.o
[ 30%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_1.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_1.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_1.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_1.cu.o
[ 31%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_k.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_k.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_k.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_k.cu.o
[ 31%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q6_k.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q6_k.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q6_k.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q6_k.cu.o
[ 31%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q8_0.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q8_0.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q8_0.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q8_0.cu.o
[ 32%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o
[ 32%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o
[ 32%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o
[ 33%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o
[ 33%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o
[ 33%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o
[ 34%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o
[ 34%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o
[ 34%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o
[ 35%] Building CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_F16 -DGGML_CUDA_FORCE_CUBLAS -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 -arch=native -Xcompiler=-fPIC -use_fast_math -Xcompiler "-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic" -MD -MT ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o -MF CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o.d -x cu -c /opt/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o
[ 35%] Linking CUDA shared library ../../../bin/libggml-cuda.so
cd /opt/llama.cpp/build/ggml/src/ggml-cuda && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/ggml-cuda.dir/link.txt --verbose=1
/usr/bin/g++ -fPIC -shared -Wl,-soname,libggml-cuda.so -o ../../../bin/libggml-cuda.so @CMakeFiles/ggml-cuda.dir/objects1.rsp @CMakeFiles/ggml-cuda.dir/linkLibs.rsp -L"/usr/local/cuda/targets/sbsa-linux/lib/stubs" -L"/usr/local/cuda/targets/sbsa-linux/lib"
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 35%] Built target ggml-cuda
/usr/bin/gmake  -f ggml/src/CMakeFiles/ggml.dir/build.make ggml/src/CMakeFiles/ggml.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/ggml/src /opt/llama.cpp/build /opt/llama.cpp/build/ggml/src /opt/llama.cpp/build/ggml/src/CMakeFiles/ggml.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f ggml/src/CMakeFiles/ggml.dir/build.make ggml/src/CMakeFiles/ggml.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 35%] Building CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o
cd /opt/llama.cpp/build/ggml/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o -MF CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o.d -o CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o -c /opt/llama.cpp/ggml/src/ggml-backend-reg.cpp
[ 36%] Linking CXX shared library ../../bin/libggml.so
cd /opt/llama.cpp/build/ggml/src && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/ggml.dir/link.txt --verbose=1
/usr/bin/c++ -fPIC -O3 -DNDEBUG -shared -Wl,-soname,libggml.so -o ../../bin/libggml.so "CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o"  -Wl,-rpath,/opt/llama.cpp/build/bin: -ldl -lstdc++fs ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so -ldl -lstdc++fs
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 36%] Built target ggml
/usr/bin/gmake  -f src/CMakeFiles/llama.dir/build.make src/CMakeFiles/llama.dir/depend
/usr/bin/gmake  -f examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/build.make examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/depend
/usr/bin/gmake  -f examples/gguf/CMakeFiles/llama-gguf.dir/build.make examples/gguf/CMakeFiles/llama-gguf.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/src /opt/llama.cpp/build /opt/llama.cpp/build/src /opt/llama.cpp/build/src/CMakeFiles/llama.dir/DependInfo.cmake "--color="
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/gguf-hash /opt/llama.cpp/build /opt/llama.cpp/build/examples/gguf-hash /opt/llama.cpp/build/examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/gguf /opt/llama.cpp/build /opt/llama.cpp/build/examples/gguf /opt/llama.cpp/build/examples/gguf/CMakeFiles/llama-gguf.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/build.make examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f src/CMakeFiles/llama.dir/build.make src/CMakeFiles/llama.dir/build
/usr/bin/gmake  -f examples/gguf/CMakeFiles/llama-gguf.dir/build.make examples/gguf/CMakeFiles/llama-gguf.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 37%] Building CXX object examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o
cd /opt/llama.cpp/build/examples/gguf-hash && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -I/opt/llama.cpp/examples -I/opt/llama.cpp/examples/gguf-hash/deps -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o -MF CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o.d -o CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o -c /opt/llama.cpp/examples/gguf-hash/gguf-hash.cpp
[ 37%] Building CXX object examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o
[ 37%] Building CXX object src/CMakeFiles/llama.dir/llama.cpp.o
cd /opt/llama.cpp/build/examples/gguf && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -I/opt/llama.cpp/examples -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o -MF CMakeFiles/llama-gguf.dir/gguf.cpp.o.d -o CMakeFiles/llama-gguf.dir/gguf.cpp.o -c /opt/llama.cpp/examples/gguf/gguf.cpp
[ 38%] Building CXX object src/CMakeFiles/llama.dir/llama-adapter.cpp.o
[ 38%] Building CXX object src/CMakeFiles/llama.dir/llama-arch.cpp.o
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama.cpp.o -MF CMakeFiles/llama.dir/llama.cpp.o.d -o CMakeFiles/llama.dir/llama.cpp.o -c /opt/llama.cpp/src/llama.cpp
[ 38%] Building CXX object src/CMakeFiles/llama.dir/llama-batch.cpp.o
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-adapter.cpp.o -MF CMakeFiles/llama.dir/llama-adapter.cpp.o.d -o CMakeFiles/llama.dir/llama-adapter.cpp.o -c /opt/llama.cpp/src/llama-adapter.cpp
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-arch.cpp.o -MF CMakeFiles/llama.dir/llama-arch.cpp.o.d -o CMakeFiles/llama.dir/llama-arch.cpp.o -c /opt/llama.cpp/src/llama-arch.cpp
[ 39%] Building CXX object src/CMakeFiles/llama.dir/llama-chat.cpp.o
[ 39%] Building CXX object src/CMakeFiles/llama.dir/llama-context.cpp.o
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-batch.cpp.o -MF CMakeFiles/llama.dir/llama-batch.cpp.o.d -o CMakeFiles/llama.dir/llama-batch.cpp.o -c /opt/llama.cpp/src/llama-batch.cpp
[ 39%] Building CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-chat.cpp.o -MF CMakeFiles/llama.dir/llama-chat.cpp.o.d -o CMakeFiles/llama.dir/llama-chat.cpp.o -c /opt/llama.cpp/src/llama-chat.cpp
[ 40%] Building CXX object src/CMakeFiles/llama.dir/llama-graph.cpp.o
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-context.cpp.o -MF CMakeFiles/llama.dir/llama-context.cpp.o.d -o CMakeFiles/llama.dir/llama-context.cpp.o -c /opt/llama.cpp/src/llama-context.cpp
[ 40%] Building CXX object src/CMakeFiles/llama.dir/llama-hparams.cpp.o
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-grammar.cpp.o -MF CMakeFiles/llama.dir/llama-grammar.cpp.o.d -o CMakeFiles/llama.dir/llama-grammar.cpp.o -c /opt/llama.cpp/src/llama-grammar.cpp
[ 40%] Building CXX object src/CMakeFiles/llama.dir/llama-impl.cpp.o
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-graph.cpp.o -MF CMakeFiles/llama.dir/llama-graph.cpp.o.d -o CMakeFiles/llama.dir/llama-graph.cpp.o -c /opt/llama.cpp/src/llama-graph.cpp
[ 41%] Building CXX object src/CMakeFiles/llama.dir/llama-io.cpp.o
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-hparams.cpp.o -MF CMakeFiles/llama.dir/llama-hparams.cpp.o.d -o CMakeFiles/llama.dir/llama-hparams.cpp.o -c /opt/llama.cpp/src/llama-hparams.cpp
[ 41%] Building CXX object src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-impl.cpp.o -MF CMakeFiles/llama.dir/llama-impl.cpp.o.d -o CMakeFiles/llama.dir/llama-impl.cpp.o -c /opt/llama.cpp/src/llama-impl.cpp
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-io.cpp.o -MF CMakeFiles/llama.dir/llama-io.cpp.o.d -o CMakeFiles/llama.dir/llama-io.cpp.o -c /opt/llama.cpp/src/llama-io.cpp
[ 41%] Building CXX object src/CMakeFiles/llama.dir/llama-memory.cpp.o
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o -MF CMakeFiles/llama.dir/llama-kv-cache.cpp.o.d -o CMakeFiles/llama.dir/llama-kv-cache.cpp.o -c /opt/llama.cpp/src/llama-kv-cache.cpp
[ 42%] Building CXX object src/CMakeFiles/llama.dir/llama-model-loader.cpp.o
[ 42%] Building CXX object src/CMakeFiles/llama.dir/llama-mmap.cpp.o
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-memory.cpp.o -MF CMakeFiles/llama.dir/llama-memory.cpp.o.d -o CMakeFiles/llama.dir/llama-memory.cpp.o -c /opt/llama.cpp/src/llama-memory.cpp
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-mmap.cpp.o -MF CMakeFiles/llama.dir/llama-mmap.cpp.o.d -o CMakeFiles/llama.dir/llama-mmap.cpp.o -c /opt/llama.cpp/src/llama-mmap.cpp
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-model-loader.cpp.o -MF CMakeFiles/llama.dir/llama-model-loader.cpp.o.d -o CMakeFiles/llama.dir/llama-model-loader.cpp.o -c /opt/llama.cpp/src/llama-model-loader.cpp
[ 43%] Building CXX object src/CMakeFiles/llama.dir/llama-model.cpp.o
[ 43%] Building CXX object src/CMakeFiles/llama.dir/llama-sampling.cpp.o
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-model.cpp.o -MF CMakeFiles/llama.dir/llama-model.cpp.o.d -o CMakeFiles/llama.dir/llama-model.cpp.o -c /opt/llama.cpp/src/llama-model.cpp
[ 43%] Building CXX object src/CMakeFiles/llama.dir/llama-quant.cpp.o
[ 43%] Building CXX object src/CMakeFiles/llama.dir/llama-vocab.cpp.o
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-sampling.cpp.o -MF CMakeFiles/llama.dir/llama-sampling.cpp.o.d -o CMakeFiles/llama.dir/llama-sampling.cpp.o -c /opt/llama.cpp/src/llama-sampling.cpp
[ 44%] Building CXX object src/CMakeFiles/llama.dir/unicode-data.cpp.o
[ 44%] Building CXX object src/CMakeFiles/llama.dir/unicode.cpp.o
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-quant.cpp.o -MF CMakeFiles/llama.dir/llama-quant.cpp.o.d -o CMakeFiles/llama.dir/llama-quant.cpp.o -c /opt/llama.cpp/src/llama-quant.cpp
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/llama-vocab.cpp.o -MF CMakeFiles/llama.dir/llama-vocab.cpp.o.d -o CMakeFiles/llama.dir/llama-vocab.cpp.o -c /opt/llama.cpp/src/llama-vocab.cpp
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/unicode-data.cpp.o -MF CMakeFiles/llama.dir/unicode-data.cpp.o.d -o CMakeFiles/llama.dir/unicode-data.cpp.o -c /opt/llama.cpp/src/unicode-data.cpp
cd /opt/llama.cpp/build/src && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT src/CMakeFiles/llama.dir/unicode.cpp.o -MF CMakeFiles/llama.dir/unicode.cpp.o.d -o CMakeFiles/llama.dir/unicode.cpp.o -c /opt/llama.cpp/src/unicode.cpp
[ 44%] Linking CXX executable ../../bin/llama-gguf
cd /opt/llama.cpp/build/examples/gguf && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-gguf.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-gguf.dir/gguf.cpp.o" -o ../../bin/llama-gguf  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 44%] Built target llama-gguf
[ 44%] Linking CXX executable ../../bin/llama-gguf-hash
cd /opt/llama.cpp/build/examples/gguf-hash && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-gguf-hash.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o" CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o CMakeFiles/sha1.dir/deps/sha1/sha1.c.o CMakeFiles/sha256.dir/deps/sha256/sha256.c.o -o ../../bin/llama-gguf-hash  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 44%] Built target llama-gguf-hash
[ 44%] Linking CXX shared library ../bin/libllama.so
cd /opt/llama.cpp/build/src && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama.dir/link.txt --verbose=1
/usr/bin/c++ -fPIC -O3 -DNDEBUG -shared -Wl,-soname,libllama.so -o ../bin/libllama.so CMakeFiles/llama.dir/llama.cpp.o "CMakeFiles/llama.dir/llama-adapter.cpp.o" "CMakeFiles/llama.dir/llama-arch.cpp.o" "CMakeFiles/llama.dir/llama-batch.cpp.o" "CMakeFiles/llama.dir/llama-chat.cpp.o" "CMakeFiles/llama.dir/llama-context.cpp.o" "CMakeFiles/llama.dir/llama-grammar.cpp.o" "CMakeFiles/llama.dir/llama-graph.cpp.o" "CMakeFiles/llama.dir/llama-hparams.cpp.o" "CMakeFiles/llama.dir/llama-impl.cpp.o" "CMakeFiles/llama.dir/llama-io.cpp.o" "CMakeFiles/llama.dir/llama-kv-cache.cpp.o" "CMakeFiles/llama.dir/llama-memory.cpp.o" "CMakeFiles/llama.dir/llama-mmap.cpp.o" "CMakeFiles/llama.dir/llama-model-loader.cpp.o" "CMakeFiles/llama.dir/llama-model.cpp.o" "CMakeFiles/llama.dir/llama-quant.cpp.o" "CMakeFiles/llama.dir/llama-sampling.cpp.o" "CMakeFiles/llama.dir/llama-vocab.cpp.o" "CMakeFiles/llama.dir/unicode-data.cpp.o" CMakeFiles/llama.dir/unicode.cpp.o  -Wl,-rpath,/opt/llama.cpp/build/bin: ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 44%] Built target llama
/usr/bin/gmake  -f common/CMakeFiles/common.dir/build.make common/CMakeFiles/common.dir/depend
/usr/bin/gmake  -f tests/CMakeFiles/test-c.dir/build.make tests/CMakeFiles/test-c.dir/depend
/usr/bin/gmake  -f examples/simple/CMakeFiles/llama-simple.dir/build.make examples/simple/CMakeFiles/llama-simple.dir/depend
/usr/bin/gmake  -f examples/simple-chat/CMakeFiles/llama-simple-chat.dir/build.make examples/simple-chat/CMakeFiles/llama-simple-chat.dir/depend
/usr/bin/gmake  -f examples/quantize-stats/CMakeFiles/llama-quantize-stats.dir/build.make examples/quantize-stats/CMakeFiles/llama-quantize-stats.dir/depend
/usr/bin/gmake  -f examples/llava/CMakeFiles/llava.dir/build.make examples/llava/CMakeFiles/llava.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/common /opt/llama.cpp/build /opt/llama.cpp/build/common /opt/llama.cpp/build/common/CMakeFiles/common.dir/DependInfo.cmake "--color="
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-c.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/simple /opt/llama.cpp/build /opt/llama.cpp/build/examples/simple /opt/llama.cpp/build/examples/simple/CMakeFiles/llama-simple.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/simple-chat /opt/llama.cpp/build /opt/llama.cpp/build/examples/simple-chat /opt/llama.cpp/build/examples/simple-chat/CMakeFiles/llama-simple-chat.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/quantize-stats /opt/llama.cpp/build /opt/llama.cpp/build/examples/quantize-stats /opt/llama.cpp/build/examples/quantize-stats/CMakeFiles/llama-quantize-stats.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/llava /opt/llama.cpp/build /opt/llama.cpp/build/examples/llava /opt/llama.cpp/build/examples/llava/CMakeFiles/llava.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-c.dir/build.make tests/CMakeFiles/test-c.dir/build
/usr/bin/gmake  -f common/CMakeFiles/common.dir/build.make common/CMakeFiles/common.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/simple/CMakeFiles/llama-simple.dir/build.make examples/simple/CMakeFiles/llama-simple.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/simple-chat/CMakeFiles/llama-simple-chat.dir/build.make examples/simple-chat/CMakeFiles/llama-simple-chat.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/quantize-stats/CMakeFiles/llama-quantize-stats.dir/build.make examples/quantize-stats/CMakeFiles/llama-quantize-stats.dir/build
/usr/bin/gmake  -f examples/llava/CMakeFiles/llava.dir/build.make examples/llava/CMakeFiles/llava.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 47%] Building CXX object common/CMakeFiles/common.dir/arg.cpp.o
[ 47%] Building CXX object examples/simple/CMakeFiles/llama-simple.dir/simple.cpp.o
[ 47%] Building C object tests/CMakeFiles/test-c.dir/test-c.c.o
[ 47%] Building CXX object common/CMakeFiles/common.dir/chat.cpp.o
[ 47%] Building CXX object examples/simple-chat/CMakeFiles/llama-simple-chat.dir/simple-chat.cpp.o
cd /opt/llama.cpp/build/common && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT common/CMakeFiles/common.dir/arg.cpp.o -MF CMakeFiles/common.dir/arg.cpp.o.d -o CMakeFiles/common.dir/arg.cpp.o -c /opt/llama.cpp/common/arg.cpp
cd /opt/llama.cpp/build/examples/simple && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/opt/llama.cpp/examples -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/simple/CMakeFiles/llama-simple.dir/simple.cpp.o -MF CMakeFiles/llama-simple.dir/simple.cpp.o.d -o CMakeFiles/llama-simple.dir/simple.cpp.o -c /opt/llama.cpp/examples/simple/simple.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/cc -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -MD -MT tests/CMakeFiles/test-c.dir/test-c.c.o -MF CMakeFiles/test-c.dir/test-c.c.o.d -o CMakeFiles/test-c.dir/test-c.c.o -c /opt/llama.cpp/tests/test-c.c
[ 47%] Building CXX object common/CMakeFiles/common.dir/common.cpp.o
cd /opt/llama.cpp/build/examples/simple-chat && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/opt/llama.cpp/examples -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/simple-chat/CMakeFiles/llama-simple-chat.dir/simple-chat.cpp.o -MF CMakeFiles/llama-simple-chat.dir/simple-chat.cpp.o.d -o CMakeFiles/llama-simple-chat.dir/simple-chat.cpp.o -c /opt/llama.cpp/examples/simple-chat/simple-chat.cpp
cd /opt/llama.cpp/build/common && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT common/CMakeFiles/common.dir/chat.cpp.o -MF CMakeFiles/common.dir/chat.cpp.o.d -o CMakeFiles/common.dir/chat.cpp.o -c /opt/llama.cpp/common/chat.cpp
[ 48%] Building CXX object examples/quantize-stats/CMakeFiles/llama-quantize-stats.dir/quantize-stats.cpp.o
[ 50%] Building CXX object common/CMakeFiles/common.dir/console.cpp.o
[ 50%] Building CXX object examples/llava/CMakeFiles/llava.dir/llava.cpp.o
cd /opt/llama.cpp/build/common && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT common/CMakeFiles/common.dir/common.cpp.o -MF CMakeFiles/common.dir/common.cpp.o.d -o CMakeFiles/common.dir/common.cpp.o -c /opt/llama.cpp/common/common.cpp
[ 50%] Building CXX object common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o
cd /opt/llama.cpp/build/examples/quantize-stats && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/opt/llama.cpp/examples -I/opt/llama.cpp/examples/quantize-stats/../../common -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/quantize-stats/CMakeFiles/llama-quantize-stats.dir/quantize-stats.cpp.o -MF CMakeFiles/llama-quantize-stats.dir/quantize-stats.cpp.o.d -o CMakeFiles/llama-quantize-stats.dir/quantize-stats.cpp.o -c /opt/llama.cpp/examples/quantize-stats/quantize-stats.cpp
cd /opt/llama.cpp/build/examples/llava && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -I/opt/llama.cpp/examples -I/opt/llama.cpp/examples/llava/. -I/opt/llama.cpp/examples/llava/../.. -I/opt/llama.cpp/examples/llava/../../common -I/opt/llama.cpp/ggml/src/../include -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-cast-qual -MD -MT examples/llava/CMakeFiles/llava.dir/llava.cpp.o -MF CMakeFiles/llava.dir/llava.cpp.o.d -o CMakeFiles/llava.dir/llava.cpp.o -c /opt/llama.cpp/examples/llava/llava.cpp
cd /opt/llama.cpp/build/common && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT common/CMakeFiles/common.dir/console.cpp.o -MF CMakeFiles/common.dir/console.cpp.o.d -o CMakeFiles/common.dir/console.cpp.o -c /opt/llama.cpp/common/console.cpp
[ 50%] Building CXX object examples/llava/CMakeFiles/llava.dir/clip.cpp.o
[ 50%] Building CXX object common/CMakeFiles/common.dir/llguidance.cpp.o
cd /opt/llama.cpp/build/common && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o -MF CMakeFiles/common.dir/json-schema-to-grammar.cpp.o.d -o CMakeFiles/common.dir/json-schema-to-grammar.cpp.o -c /opt/llama.cpp/common/json-schema-to-grammar.cpp
[ 51%] Building CXX object common/CMakeFiles/common.dir/log.cpp.o
[ 51%] Building CXX object common/CMakeFiles/common.dir/ngram-cache.cpp.o
cd /opt/llama.cpp/build/examples/llava && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -I/opt/llama.cpp/examples -I/opt/llama.cpp/examples/llava/. -I/opt/llama.cpp/examples/llava/../.. -I/opt/llama.cpp/examples/llava/../../common -I/opt/llama.cpp/ggml/src/../include -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-cast-qual -MD -MT examples/llava/CMakeFiles/llava.dir/clip.cpp.o -MF CMakeFiles/llava.dir/clip.cpp.o.d -o CMakeFiles/llava.dir/clip.cpp.o -c /opt/llama.cpp/examples/llava/clip.cpp
cd /opt/llama.cpp/build/common && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT common/CMakeFiles/common.dir/llguidance.cpp.o -MF CMakeFiles/common.dir/llguidance.cpp.o.d -o CMakeFiles/common.dir/llguidance.cpp.o -c /opt/llama.cpp/common/llguidance.cpp
[ 51%] Building CXX object common/CMakeFiles/common.dir/sampling.cpp.o
cd /opt/llama.cpp/build/common && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT common/CMakeFiles/common.dir/log.cpp.o -MF CMakeFiles/common.dir/log.cpp.o.d -o CMakeFiles/common.dir/log.cpp.o -c /opt/llama.cpp/common/log.cpp
[ 52%] Building CXX object common/CMakeFiles/common.dir/speculative.cpp.o
cd /opt/llama.cpp/build/common && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT common/CMakeFiles/common.dir/ngram-cache.cpp.o -MF CMakeFiles/common.dir/ngram-cache.cpp.o.d -o CMakeFiles/common.dir/ngram-cache.cpp.o -c /opt/llama.cpp/common/ngram-cache.cpp
cd /opt/llama.cpp/build/common && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT common/CMakeFiles/common.dir/sampling.cpp.o -MF CMakeFiles/common.dir/sampling.cpp.o.d -o CMakeFiles/common.dir/sampling.cpp.o -c /opt/llama.cpp/common/sampling.cpp
cd /opt/llama.cpp/build/common && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT common/CMakeFiles/common.dir/speculative.cpp.o -MF CMakeFiles/common.dir/speculative.cpp.o.d -o CMakeFiles/common.dir/speculative.cpp.o -c /opt/llama.cpp/common/speculative.cpp
[ 52%] Linking C executable ../bin/test-c
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-c.dir/link.txt --verbose=1
/usr/bin/cc -O3 -DNDEBUG "CMakeFiles/test-c.dir/test-c.c.o" -o ../bin/test-c  -Wl,-rpath,/opt/llama.cpp/build/bin ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 52%] Built target test-c
[ 52%] Linking CXX executable ../../bin/llama-simple
cd /opt/llama.cpp/build/examples/simple && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-simple.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-simple.dir/simple.cpp.o" -o ../../bin/llama-simple  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 52%] Built target llama-simple
[ 53%] Linking CXX executable ../../bin/llama-simple-chat
cd /opt/llama.cpp/build/examples/simple-chat && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-simple-chat.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-simple-chat.dir/simple-chat.cpp.o" -o ../../bin/llama-simple-chat  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 53%] Built target llama-simple-chat
[ 53%] Linking CXX executable ../../bin/llama-quantize-stats
cd /opt/llama.cpp/build/examples/quantize-stats && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-quantize-stats.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-quantize-stats.dir/quantize-stats.cpp.o" "../../common/CMakeFiles/build_info.dir/build-info.cpp.o" -o ../../bin/llama-quantize-stats  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 53%] Built target llama-quantize-stats
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 53%] Built target llava
/usr/bin/gmake  -f examples/llava/CMakeFiles/llava_static.dir/build.make examples/llava/CMakeFiles/llava_static.dir/depend
/usr/bin/gmake  -f examples/llava/CMakeFiles/llava_shared.dir/build.make examples/llava/CMakeFiles/llava_shared.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/llava /opt/llama.cpp/build /opt/llama.cpp/build/examples/llava /opt/llama.cpp/build/examples/llava/CMakeFiles/llava_static.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/llava /opt/llama.cpp/build /opt/llama.cpp/build/examples/llava /opt/llama.cpp/build/examples/llava/CMakeFiles/llava_shared.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/llava/CMakeFiles/llava_static.dir/build.make examples/llava/CMakeFiles/llava_static.dir/build
/usr/bin/gmake  -f examples/llava/CMakeFiles/llava_shared.dir/build.make examples/llava/CMakeFiles/llava_shared.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 54%] Linking CXX shared library ../../bin/libllava_shared.so
[ 54%] Linking CXX static library libllava_static.a
cd /opt/llama.cpp/build/examples/llava && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llava_shared.dir/link.txt --verbose=1
cd /opt/llama.cpp/build/examples/llava && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -P CMakeFiles/llava_static.dir/cmake_clean_target.cmake
/usr/bin/c++ -fPIC -O3 -DNDEBUG -shared -Wl,-soname,libllava_shared.so -o ../../bin/libllava_shared.so CMakeFiles/llava.dir/llava.cpp.o CMakeFiles/llava.dir/clip.cpp.o  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
cd /opt/llama.cpp/build/examples/llava && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llava_static.dir/link.txt --verbose=1
/usr/bin/ar qc libllava_static.a CMakeFiles/llava.dir/llava.cpp.o CMakeFiles/llava.dir/clip.cpp.o
/usr/bin/ranlib libllava_static.a
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 54%] Built target llava_static
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 54%] Built target llava_shared
[ 54%] Linking CXX static library libcommon.a
cd /opt/llama.cpp/build/common && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -P CMakeFiles/common.dir/cmake_clean_target.cmake
cd /opt/llama.cpp/build/common && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/common.dir/link.txt --verbose=1
/usr/bin/ar qc libcommon.a CMakeFiles/common.dir/arg.cpp.o CMakeFiles/common.dir/chat.cpp.o CMakeFiles/common.dir/common.cpp.o CMakeFiles/common.dir/console.cpp.o "CMakeFiles/common.dir/json-schema-to-grammar.cpp.o" CMakeFiles/common.dir/llguidance.cpp.o CMakeFiles/common.dir/log.cpp.o "CMakeFiles/common.dir/ngram-cache.cpp.o" CMakeFiles/common.dir/sampling.cpp.o CMakeFiles/common.dir/speculative.cpp.o "CMakeFiles/build_info.dir/build-info.cpp.o"
/usr/bin/ranlib libcommon.a
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 54%] Built target common
/usr/bin/gmake  -f tests/CMakeFiles/test-tokenizer-0.dir/build.make tests/CMakeFiles/test-tokenizer-0.dir/depend
/usr/bin/gmake  -f tests/CMakeFiles/test-sampling.dir/build.make tests/CMakeFiles/test-sampling.dir/depend
/usr/bin/gmake  -f tests/CMakeFiles/test-grammar-parser.dir/build.make tests/CMakeFiles/test-grammar-parser.dir/depend
/usr/bin/gmake  -f tests/CMakeFiles/test-grammar-integration.dir/build.make tests/CMakeFiles/test-grammar-integration.dir/depend
/usr/bin/gmake  -f tests/CMakeFiles/test-llama-grammar.dir/build.make tests/CMakeFiles/test-llama-grammar.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-chat.dir/build.make tests/CMakeFiles/test-chat.dir/depend
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-tokenizer-0.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-sampling.dir/DependInfo.cmake "--color="
/usr/bin/gmake  -f tests/CMakeFiles/test-json-schema-to-grammar.dir/build.make tests/CMakeFiles/test-json-schema-to-grammar.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-grammar-parser.dir/DependInfo.cmake "--color="
/usr/bin/gmake  -f tests/CMakeFiles/test-tokenizer-1-bpe.dir/build.make tests/CMakeFiles/test-tokenizer-1-bpe.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-grammar-integration.dir/DependInfo.cmake "--color="
/usr/bin/gmake  -f tests/CMakeFiles/test-tokenizer-1-spm.dir/build.make tests/CMakeFiles/test-tokenizer-1-spm.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-llama-grammar.dir/DependInfo.cmake "--color="
/usr/bin/gmake  -f tests/CMakeFiles/test-log.dir/build.make tests/CMakeFiles/test-log.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-chat.dir/DependInfo.cmake "--color="
/usr/bin/gmake  -f tests/CMakeFiles/test-arg-parser.dir/build.make tests/CMakeFiles/test-arg-parser.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-json-schema-to-grammar.dir/DependInfo.cmake "--color="
/usr/bin/gmake  -f tests/CMakeFiles/test-chat-template.dir/build.make tests/CMakeFiles/test-chat-template.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-tokenizer-1-bpe.dir/DependInfo.cmake "--color="
/usr/bin/gmake  -f tests/CMakeFiles/test-gguf.dir/build.make tests/CMakeFiles/test-gguf.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-backend-ops.dir/build.make tests/CMakeFiles/test-backend-ops.dir/depend
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-tokenizer-1-spm.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-model-load-cancel.dir/build.make tests/CMakeFiles/test-model-load-cancel.dir/depend
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-log.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-autorelease.dir/build.make tests/CMakeFiles/test-autorelease.dir/depend
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-arg-parser.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-chat-template.dir/DependInfo.cmake "--color="
/usr/bin/gmake  -f tests/CMakeFiles/test-barrier.dir/build.make tests/CMakeFiles/test-barrier.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-quantize-fns.dir/build.make tests/CMakeFiles/test-quantize-fns.dir/depend
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-gguf.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-backend-ops.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-quantize-perf.dir/build.make tests/CMakeFiles/test-quantize-perf.dir/depend
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-tokenizer-0.dir/build.make tests/CMakeFiles/test-tokenizer-0.dir/build
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-model-load-cancel.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-autorelease.dir/DependInfo.cmake "--color="
/usr/bin/gmake  -f tests/CMakeFiles/test-sampling.dir/build.make tests/CMakeFiles/test-sampling.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-grammar-parser.dir/build.make tests/CMakeFiles/test-grammar-parser.dir/build
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-barrier.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-quantize-fns.dir/DependInfo.cmake "--color="
/usr/bin/gmake  -f tests/CMakeFiles/test-grammar-integration.dir/build.make tests/CMakeFiles/test-grammar-integration.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-llama-grammar.dir/build.make tests/CMakeFiles/test-llama-grammar.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-quantize-perf.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-chat.dir/build.make tests/CMakeFiles/test-chat.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-json-schema-to-grammar.dir/build.make tests/CMakeFiles/test-json-schema-to-grammar.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-tokenizer-1-bpe.dir/build.make tests/CMakeFiles/test-tokenizer-1-bpe.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-tokenizer-1-spm.dir/build.make tests/CMakeFiles/test-tokenizer-1-spm.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-log.dir/build.make tests/CMakeFiles/test-log.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-arg-parser.dir/build.make tests/CMakeFiles/test-arg-parser.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-chat-template.dir/build.make tests/CMakeFiles/test-chat-template.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-gguf.dir/build.make tests/CMakeFiles/test-gguf.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-backend-ops.dir/build.make tests/CMakeFiles/test-backend-ops.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-model-load-cancel.dir/build.make tests/CMakeFiles/test-model-load-cancel.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 54%] Building CXX object tests/CMakeFiles/test-tokenizer-0.dir/test-tokenizer-0.cpp.o
/usr/bin/gmake  -f tests/CMakeFiles/test-autorelease.dir/build.make tests/CMakeFiles/test-autorelease.dir/build
[ 54%] Building CXX object tests/CMakeFiles/test-sampling.dir/test-sampling.cpp.o
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-tokenizer-0.dir/test-tokenizer-0.cpp.o -MF CMakeFiles/test-tokenizer-0.dir/test-tokenizer-0.cpp.o.d -o CMakeFiles/test-tokenizer-0.dir/test-tokenizer-0.cpp.o -c /opt/llama.cpp/tests/test-tokenizer-0.cpp
/usr/bin/gmake  -f tests/CMakeFiles/test-barrier.dir/build.make tests/CMakeFiles/test-barrier.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-sampling.dir/test-sampling.cpp.o -MF CMakeFiles/test-sampling.dir/test-sampling.cpp.o.d -o CMakeFiles/test-sampling.dir/test-sampling.cpp.o -c /opt/llama.cpp/tests/test-sampling.cpp
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 55%] Building CXX object tests/CMakeFiles/test-sampling.dir/get-model.cpp.o
[ 55%] Building CXX object tests/CMakeFiles/test-grammar-parser.dir/test-grammar-parser.cpp.o
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-quantize-fns.dir/build.make tests/CMakeFiles/test-quantize-fns.dir/build
[ 56%] Building CXX object tests/CMakeFiles/test-grammar-parser.dir/get-model.cpp.o
[ 56%] Building CXX object tests/CMakeFiles/test-grammar-integration.dir/test-grammar-integration.cpp.o
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-sampling.dir/get-model.cpp.o -MF CMakeFiles/test-sampling.dir/get-model.cpp.o.d -o CMakeFiles/test-sampling.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-grammar-parser.dir/test-grammar-parser.cpp.o -MF CMakeFiles/test-grammar-parser.dir/test-grammar-parser.cpp.o.d -o CMakeFiles/test-grammar-parser.dir/test-grammar-parser.cpp.o -c /opt/llama.cpp/tests/test-grammar-parser.cpp
[ 56%] Building CXX object tests/CMakeFiles/test-llama-grammar.dir/test-llama-grammar.cpp.o
/usr/bin/gmake  -f tests/CMakeFiles/test-quantize-perf.dir/build.make tests/CMakeFiles/test-quantize-perf.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-grammar-integration.dir/test-grammar-integration.cpp.o -MF CMakeFiles/test-grammar-integration.dir/test-grammar-integration.cpp.o.d -o CMakeFiles/test-grammar-integration.dir/test-grammar-integration.cpp.o -c /opt/llama.cpp/tests/test-grammar-integration.cpp
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-llama-grammar.dir/test-llama-grammar.cpp.o -MF CMakeFiles/test-llama-grammar.dir/test-llama-grammar.cpp.o.d -o CMakeFiles/test-llama-grammar.dir/test-llama-grammar.cpp.o -c /opt/llama.cpp/tests/test-llama-grammar.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-grammar-parser.dir/get-model.cpp.o -MF CMakeFiles/test-grammar-parser.dir/get-model.cpp.o.d -o CMakeFiles/test-grammar-parser.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
[ 58%] Building CXX object tests/CMakeFiles/test-chat.dir/test-chat.cpp.o
[ 58%] Building CXX object tests/CMakeFiles/test-grammar-integration.dir/get-model.cpp.o
[ 58%] Building CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/test-json-schema-to-grammar.cpp.o
[ 58%] Building CXX object tests/CMakeFiles/test-llama-grammar.dir/get-model.cpp.o
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-rope.dir/build.make tests/CMakeFiles/test-rope.dir/depend
[ 59%] Building CXX object tests/CMakeFiles/test-chat.dir/get-model.cpp.o
[ 60%] Building CXX object tests/CMakeFiles/test-tokenizer-1-bpe.dir/test-tokenizer-1-bpe.cpp.o
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-chat.dir/test-chat.cpp.o -MF CMakeFiles/test-chat.dir/test-chat.cpp.o.d -o CMakeFiles/test-chat.dir/test-chat.cpp.o -c /opt/llama.cpp/tests/test-chat.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-grammar-integration.dir/get-model.cpp.o -MF CMakeFiles/test-grammar-integration.dir/get-model.cpp.o.d -o CMakeFiles/test-grammar-integration.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/tests/../examples/server -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-json-schema-to-grammar.dir/test-json-schema-to-grammar.cpp.o -MF CMakeFiles/test-json-schema-to-grammar.dir/test-json-schema-to-grammar.cpp.o.d -o CMakeFiles/test-json-schema-to-grammar.dir/test-json-schema-to-grammar.cpp.o -c /opt/llama.cpp/tests/test-json-schema-to-grammar.cpp
[ 60%] Building CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/get-model.cpp.o
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-llama-grammar.dir/get-model.cpp.o -MF CMakeFiles/test-llama-grammar.dir/get-model.cpp.o.d -o CMakeFiles/test-llama-grammar.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-tokenizer-1-bpe.dir/test-tokenizer-1-bpe.cpp.o -MF CMakeFiles/test-tokenizer-1-bpe.dir/test-tokenizer-1-bpe.cpp.o.d -o CMakeFiles/test-tokenizer-1-bpe.dir/test-tokenizer-1-bpe.cpp.o -c /opt/llama.cpp/tests/test-tokenizer-1-bpe.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-chat.dir/get-model.cpp.o -MF CMakeFiles/test-chat.dir/get-model.cpp.o.d -o CMakeFiles/test-chat.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
[ 61%] Building CXX object tests/CMakeFiles/test-tokenizer-1-spm.dir/test-tokenizer-1-spm.cpp.o
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 61%] Building CXX object tests/CMakeFiles/test-log.dir/test-log.cpp.o
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/tests/../examples/server -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-json-schema-to-grammar.dir/get-model.cpp.o -MF CMakeFiles/test-json-schema-to-grammar.dir/get-model.cpp.o.d -o CMakeFiles/test-json-schema-to-grammar.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-tokenizer-1-spm.dir/test-tokenizer-1-spm.cpp.o -MF CMakeFiles/test-tokenizer-1-spm.dir/test-tokenizer-1-spm.cpp.o.d -o CMakeFiles/test-tokenizer-1-spm.dir/test-tokenizer-1-spm.cpp.o -c /opt/llama.cpp/tests/test-tokenizer-1-spm.cpp
[ 62%] Building CXX object tests/CMakeFiles/test-log.dir/get-model.cpp.o
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-log.dir/test-log.cpp.o -MF CMakeFiles/test-log.dir/test-log.cpp.o.d -o CMakeFiles/test-log.dir/test-log.cpp.o -c /opt/llama.cpp/tests/test-log.cpp
[ 63%] Building CXX object tests/CMakeFiles/test-arg-parser.dir/test-arg-parser.cpp.o
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-log.dir/get-model.cpp.o -MF CMakeFiles/test-log.dir/get-model.cpp.o.d -o CMakeFiles/test-log.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
[ 63%] Building CXX object tests/CMakeFiles/test-chat-template.dir/test-chat-template.cpp.o
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 63%] Building CXX object tests/CMakeFiles/test-arg-parser.dir/get-model.cpp.o
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-arg-parser.dir/test-arg-parser.cpp.o -MF CMakeFiles/test-arg-parser.dir/test-arg-parser.cpp.o.d -o CMakeFiles/test-arg-parser.dir/test-arg-parser.cpp.o -c /opt/llama.cpp/tests/test-arg-parser.cpp
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/tests /opt/llama.cpp/build /opt/llama.cpp/build/tests /opt/llama.cpp/build/tests/CMakeFiles/test-rope.dir/DependInfo.cmake "--color="
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-chat-template.dir/test-chat-template.cpp.o -MF CMakeFiles/test-chat-template.dir/test-chat-template.cpp.o.d -o CMakeFiles/test-chat-template.dir/test-chat-template.cpp.o -c /opt/llama.cpp/tests/test-chat-template.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-arg-parser.dir/get-model.cpp.o -MF CMakeFiles/test-arg-parser.dir/get-model.cpp.o.d -o CMakeFiles/test-arg-parser.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
[ 64%] Building CXX object tests/CMakeFiles/test-chat-template.dir/get-model.cpp.o
[ 64%] Building CXX object tests/CMakeFiles/test-gguf.dir/test-gguf.cpp.o
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-chat-template.dir/get-model.cpp.o -MF CMakeFiles/test-chat-template.dir/get-model.cpp.o.d -o CMakeFiles/test-chat-template.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-gguf.dir/test-gguf.cpp.o -MF CMakeFiles/test-gguf.dir/test-gguf.cpp.o.d -o CMakeFiles/test-gguf.dir/test-gguf.cpp.o -c /opt/llama.cpp/tests/test-gguf.cpp
[ 66%] Building CXX object tests/CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o
[ 66%] Building CXX object tests/CMakeFiles/test-gguf.dir/get-model.cpp.o
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o -MF CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o.d -o CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o -c /opt/llama.cpp/tests/test-backend-ops.cpp
[ 66%] Building CXX object tests/CMakeFiles/test-backend-ops.dir/get-model.cpp.o
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-gguf.dir/get-model.cpp.o -MF CMakeFiles/test-gguf.dir/get-model.cpp.o.d -o CMakeFiles/test-gguf.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
[ 66%] Building CXX object tests/CMakeFiles/test-model-load-cancel.dir/test-model-load-cancel.cpp.o
[ 67%] Building CXX object tests/CMakeFiles/test-autorelease.dir/test-autorelease.cpp.o
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-backend-ops.dir/get-model.cpp.o -MF CMakeFiles/test-backend-ops.dir/get-model.cpp.o.d -o CMakeFiles/test-backend-ops.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-model-load-cancel.dir/test-model-load-cancel.cpp.o -MF CMakeFiles/test-model-load-cancel.dir/test-model-load-cancel.cpp.o.d -o CMakeFiles/test-model-load-cancel.dir/test-model-load-cancel.cpp.o -c /opt/llama.cpp/tests/test-model-load-cancel.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-autorelease.dir/test-autorelease.cpp.o -MF CMakeFiles/test-autorelease.dir/test-autorelease.cpp.o.d -o CMakeFiles/test-autorelease.dir/test-autorelease.cpp.o -c /opt/llama.cpp/tests/test-autorelease.cpp
[ 68%] Building CXX object tests/CMakeFiles/test-model-load-cancel.dir/get-model.cpp.o
[ 69%] Building CXX object tests/CMakeFiles/test-barrier.dir/test-barrier.cpp.o
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-model-load-cancel.dir/get-model.cpp.o -MF CMakeFiles/test-model-load-cancel.dir/get-model.cpp.o.d -o CMakeFiles/test-model-load-cancel.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-barrier.dir/test-barrier.cpp.o -MF CMakeFiles/test-barrier.dir/test-barrier.cpp.o.d -o CMakeFiles/test-barrier.dir/test-barrier.cpp.o -c /opt/llama.cpp/tests/test-barrier.cpp
[ 69%] Building CXX object tests/CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o
[ 69%] Building CXX object tests/CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o -MF CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o.d -o CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o -c /opt/llama.cpp/tests/test-quantize-fns.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o -MF CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o.d -o CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o -c /opt/llama.cpp/tests/test-quantize-perf.cpp
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f tests/CMakeFiles/test-rope.dir/build.make tests/CMakeFiles/test-rope.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 69%] Building CXX object tests/CMakeFiles/test-rope.dir/test-rope.cpp.o
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-rope.dir/test-rope.cpp.o -MF CMakeFiles/test-rope.dir/test-rope.cpp.o.d -o CMakeFiles/test-rope.dir/test-rope.cpp.o -c /opt/llama.cpp/tests/test-rope.cpp
/usr/bin/gmake  -f examples/batched-bench/CMakeFiles/llama-batched-bench.dir/build.make examples/batched-bench/CMakeFiles/llama-batched-bench.dir/depend
/usr/bin/gmake  -f examples/batched/CMakeFiles/llama-batched.dir/build.make examples/batched/CMakeFiles/llama-batched.dir/depend
/usr/bin/gmake  -f examples/embedding/CMakeFiles/llama-embedding.dir/build.make examples/embedding/CMakeFiles/llama-embedding.dir/depend
/usr/bin/gmake  -f examples/eval-callback/CMakeFiles/llama-eval-callback.dir/build.make examples/eval-callback/CMakeFiles/llama-eval-callback.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/batched-bench /opt/llama.cpp/build /opt/llama.cpp/build/examples/batched-bench /opt/llama.cpp/build/examples/batched-bench/CMakeFiles/llama-batched-bench.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/batched /opt/llama.cpp/build /opt/llama.cpp/build/examples/batched /opt/llama.cpp/build/examples/batched/CMakeFiles/llama-batched.dir/DependInfo.cmake "--color="
/usr/bin/gmake  -f examples/gbnf-validator/CMakeFiles/llama-gbnf-validator.dir/build.make examples/gbnf-validator/CMakeFiles/llama-gbnf-validator.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/embedding /opt/llama.cpp/build /opt/llama.cpp/build/examples/embedding /opt/llama.cpp/build/examples/embedding/CMakeFiles/llama-embedding.dir/DependInfo.cmake "--color="
/usr/bin/gmake  -f examples/gguf-split/CMakeFiles/llama-gguf-split.dir/build.make examples/gguf-split/CMakeFiles/llama-gguf-split.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/eval-callback /opt/llama.cpp/build /opt/llama.cpp/build/examples/eval-callback /opt/llama.cpp/build/examples/eval-callback/CMakeFiles/llama-eval-callback.dir/DependInfo.cmake "--color="
/usr/bin/gmake  -f examples/gritlm/CMakeFiles/llama-gritlm.dir/build.make examples/gritlm/CMakeFiles/llama-gritlm.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/gbnf-validator /opt/llama.cpp/build /opt/llama.cpp/build/examples/gbnf-validator /opt/llama.cpp/build/examples/gbnf-validator/CMakeFiles/llama-gbnf-validator.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/gguf-split /opt/llama.cpp/build /opt/llama.cpp/build/examples/gguf-split /opt/llama.cpp/build/examples/gguf-split/CMakeFiles/llama-gguf-split.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 72%] Building CXX object tests/CMakeFiles/test-autorelease.dir/get-model.cpp.o
[ 72%] Building CXX object tests/CMakeFiles/test-barrier.dir/get-model.cpp.o
[ 72%] Building CXX object tests/CMakeFiles/test-rope.dir/get-model.cpp.o
[ 72%] Building CXX object tests/CMakeFiles/test-quantize-fns.dir/get-model.cpp.o
[ 72%] Building CXX object tests/CMakeFiles/test-quantize-perf.dir/get-model.cpp.o
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/gritlm /opt/llama.cpp/build /opt/llama.cpp/build/examples/gritlm /opt/llama.cpp/build/examples/gritlm/CMakeFiles/llama-gritlm.dir/DependInfo.cmake "--color="
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-autorelease.dir/get-model.cpp.o -MF CMakeFiles/test-autorelease.dir/get-model.cpp.o.d -o CMakeFiles/test-autorelease.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-barrier.dir/get-model.cpp.o -MF CMakeFiles/test-barrier.dir/get-model.cpp.o.d -o CMakeFiles/test-barrier.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-rope.dir/get-model.cpp.o -MF CMakeFiles/test-rope.dir/get-model.cpp.o.d -o CMakeFiles/test-rope.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-quantize-fns.dir/get-model.cpp.o -MF CMakeFiles/test-quantize-fns.dir/get-model.cpp.o.d -o CMakeFiles/test-quantize-fns.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
cd /opt/llama.cpp/build/tests && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT tests/CMakeFiles/test-quantize-perf.dir/get-model.cpp.o -MF CMakeFiles/test-quantize-perf.dir/get-model.cpp.o.d -o CMakeFiles/test-quantize-perf.dir/get-model.cpp.o -c /opt/llama.cpp/tests/get-model.cpp
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/batched-bench/CMakeFiles/llama-batched-bench.dir/build.make examples/batched-bench/CMakeFiles/llama-batched-bench.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/batched/CMakeFiles/llama-batched.dir/build.make examples/batched/CMakeFiles/llama-batched.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/embedding/CMakeFiles/llama-embedding.dir/build.make examples/embedding/CMakeFiles/llama-embedding.dir/build
/usr/bin/gmake  -f examples/eval-callback/CMakeFiles/llama-eval-callback.dir/build.make examples/eval-callback/CMakeFiles/llama-eval-callback.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/gbnf-validator/CMakeFiles/llama-gbnf-validator.dir/build.make examples/gbnf-validator/CMakeFiles/llama-gbnf-validator.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/gguf-split/CMakeFiles/llama-gguf-split.dir/build.make examples/gguf-split/CMakeFiles/llama-gguf-split.dir/build
/usr/bin/gmake  -f examples/gritlm/CMakeFiles/llama-gritlm.dir/build.make examples/gritlm/CMakeFiles/llama-gritlm.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 72%] Building CXX object examples/batched-bench/CMakeFiles/llama-batched-bench.dir/batched-bench.cpp.o
cd /opt/llama.cpp/build/examples/batched-bench && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/batched-bench/CMakeFiles/llama-batched-bench.dir/batched-bench.cpp.o -MF CMakeFiles/llama-batched-bench.dir/batched-bench.cpp.o.d -o CMakeFiles/llama-batched-bench.dir/batched-bench.cpp.o -c /opt/llama.cpp/examples/batched-bench/batched-bench.cpp
[ 73%] Building CXX object examples/batched/CMakeFiles/llama-batched.dir/batched.cpp.o
[ 73%] Building CXX object examples/embedding/CMakeFiles/llama-embedding.dir/embedding.cpp.o
cd /opt/llama.cpp/build/examples/batched && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/batched/CMakeFiles/llama-batched.dir/batched.cpp.o -MF CMakeFiles/llama-batched.dir/batched.cpp.o.d -o CMakeFiles/llama-batched.dir/batched.cpp.o -c /opt/llama.cpp/examples/batched/batched.cpp
[ 74%] Building CXX object examples/eval-callback/CMakeFiles/llama-eval-callback.dir/eval-callback.cpp.o
cd /opt/llama.cpp/build/examples/embedding && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/embedding/CMakeFiles/llama-embedding.dir/embedding.cpp.o -MF CMakeFiles/llama-embedding.dir/embedding.cpp.o.d -o CMakeFiles/llama-embedding.dir/embedding.cpp.o -c /opt/llama.cpp/examples/embedding/embedding.cpp
cd /opt/llama.cpp/build/examples/eval-callback && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/eval-callback/CMakeFiles/llama-eval-callback.dir/eval-callback.cpp.o -MF CMakeFiles/llama-eval-callback.dir/eval-callback.cpp.o.d -o CMakeFiles/llama-eval-callback.dir/eval-callback.cpp.o -c /opt/llama.cpp/examples/eval-callback/eval-callback.cpp
[ 74%] Building CXX object examples/gbnf-validator/CMakeFiles/llama-gbnf-validator.dir/gbnf-validator.cpp.o
cd /opt/llama.cpp/build/examples/gbnf-validator && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/gbnf-validator/CMakeFiles/llama-gbnf-validator.dir/gbnf-validator.cpp.o -MF CMakeFiles/llama-gbnf-validator.dir/gbnf-validator.cpp.o.d -o CMakeFiles/llama-gbnf-validator.dir/gbnf-validator.cpp.o -c /opt/llama.cpp/examples/gbnf-validator/gbnf-validator.cpp
[ 74%] Building CXX object examples/gguf-split/CMakeFiles/llama-gguf-split.dir/gguf-split.cpp.o
[ 74%] Building CXX object examples/gritlm/CMakeFiles/llama-gritlm.dir/gritlm.cpp.o
cd /opt/llama.cpp/build/examples/gguf-split && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/gguf-split/CMakeFiles/llama-gguf-split.dir/gguf-split.cpp.o -MF CMakeFiles/llama-gguf-split.dir/gguf-split.cpp.o.d -o CMakeFiles/llama-gguf-split.dir/gguf-split.cpp.o -c /opt/llama.cpp/examples/gguf-split/gguf-split.cpp
cd /opt/llama.cpp/build/examples/gritlm && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/gritlm/CMakeFiles/llama-gritlm.dir/gritlm.cpp.o -MF CMakeFiles/llama-gritlm.dir/gritlm.cpp.o.d -o CMakeFiles/llama-gritlm.dir/gritlm.cpp.o -c /opt/llama.cpp/examples/gritlm/gritlm.cpp
[ 74%] Linking CXX executable ../bin/test-model-load-cancel
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-model-load-cancel.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-model-load-cancel.dir/test-model-load-cancel.cpp.o" "CMakeFiles/test-model-load-cancel.dir/get-model.cpp.o" -o ../bin/test-model-load-cancel  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
/usr/bin/gmake  -f examples/imatrix/CMakeFiles/llama-imatrix.dir/build.make examples/imatrix/CMakeFiles/llama-imatrix.dir/depend
/usr/bin/gmake  -f examples/infill/CMakeFiles/llama-infill.dir/build.make examples/infill/CMakeFiles/llama-infill.dir/depend
/usr/bin/gmake  -f examples/llama-bench/CMakeFiles/llama-bench.dir/build.make examples/llama-bench/CMakeFiles/llama-bench.dir/depend
/usr/bin/gmake  -f examples/lookahead/CMakeFiles/llama-lookahead.dir/build.make examples/lookahead/CMakeFiles/llama-lookahead.dir/depend
/usr/bin/gmake  -f examples/lookup/CMakeFiles/llama-lookup.dir/build.make examples/lookup/CMakeFiles/llama-lookup.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/imatrix /opt/llama.cpp/build /opt/llama.cpp/build/examples/imatrix /opt/llama.cpp/build/examples/imatrix/CMakeFiles/llama-imatrix.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/infill /opt/llama.cpp/build /opt/llama.cpp/build/examples/infill /opt/llama.cpp/build/examples/infill/CMakeFiles/llama-infill.dir/DependInfo.cmake "--color="
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/llama-bench /opt/llama.cpp/build /opt/llama.cpp/build/examples/llama-bench /opt/llama.cpp/build/examples/llama-bench/CMakeFiles/llama-bench.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/lookahead /opt/llama.cpp/build /opt/llama.cpp/build/examples/lookahead /opt/llama.cpp/build/examples/lookahead/CMakeFiles/llama-lookahead.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/lookup /opt/llama.cpp/build /opt/llama.cpp/build/examples/lookup /opt/llama.cpp/build/examples/lookup/CMakeFiles/llama-lookup.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/imatrix/CMakeFiles/llama-imatrix.dir/build.make examples/imatrix/CMakeFiles/llama-imatrix.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/infill/CMakeFiles/llama-infill.dir/build.make examples/infill/CMakeFiles/llama-infill.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/llama-bench/CMakeFiles/llama-bench.dir/build.make examples/llama-bench/CMakeFiles/llama-bench.dir/build
/usr/bin/gmake  -f examples/lookahead/CMakeFiles/llama-lookahead.dir/build.make examples/lookahead/CMakeFiles/llama-lookahead.dir/build
/usr/bin/gmake  -f examples/lookup/CMakeFiles/llama-lookup.dir/build.make examples/lookup/CMakeFiles/llama-lookup.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 75%] Building CXX object examples/infill/CMakeFiles/llama-infill.dir/infill.cpp.o
[ 75%] Building CXX object examples/imatrix/CMakeFiles/llama-imatrix.dir/imatrix.cpp.o
[ 75%] Building CXX object examples/llama-bench/CMakeFiles/llama-bench.dir/llama-bench.cpp.o
[ 75%] Building CXX object examples/lookahead/CMakeFiles/llama-lookahead.dir/lookahead.cpp.o
cd /opt/llama.cpp/build/examples/infill && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/infill/CMakeFiles/llama-infill.dir/infill.cpp.o -MF CMakeFiles/llama-infill.dir/infill.cpp.o.d -o CMakeFiles/llama-infill.dir/infill.cpp.o -c /opt/llama.cpp/examples/infill/infill.cpp
cd /opt/llama.cpp/build/examples/imatrix && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/imatrix/CMakeFiles/llama-imatrix.dir/imatrix.cpp.o -MF CMakeFiles/llama-imatrix.dir/imatrix.cpp.o.d -o CMakeFiles/llama-imatrix.dir/imatrix.cpp.o -c /opt/llama.cpp/examples/imatrix/imatrix.cpp
cd /opt/llama.cpp/build/examples/llama-bench && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/llama-bench/CMakeFiles/llama-bench.dir/llama-bench.cpp.o -MF CMakeFiles/llama-bench.dir/llama-bench.cpp.o.d -o CMakeFiles/llama-bench.dir/llama-bench.cpp.o -c /opt/llama.cpp/examples/llama-bench/llama-bench.cpp
cd /opt/llama.cpp/build/examples/lookahead && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/lookahead/CMakeFiles/llama-lookahead.dir/lookahead.cpp.o -MF CMakeFiles/llama-lookahead.dir/lookahead.cpp.o.d -o CMakeFiles/llama-lookahead.dir/lookahead.cpp.o -c /opt/llama.cpp/examples/lookahead/lookahead.cpp
[ 75%] Building CXX object examples/lookup/CMakeFiles/llama-lookup.dir/lookup.cpp.o
cd /opt/llama.cpp/build/examples/lookup && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/lookup/CMakeFiles/llama-lookup.dir/lookup.cpp.o -MF CMakeFiles/llama-lookup.dir/lookup.cpp.o.d -o CMakeFiles/llama-lookup.dir/lookup.cpp.o -c /opt/llama.cpp/examples/lookup/lookup.cpp
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 75%] Built target test-model-load-cancel
/usr/bin/gmake  -f examples/lookup/CMakeFiles/llama-lookup-create.dir/build.make examples/lookup/CMakeFiles/llama-lookup-create.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/lookup /opt/llama.cpp/build /opt/llama.cpp/build/examples/lookup /opt/llama.cpp/build/examples/lookup/CMakeFiles/llama-lookup-create.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/lookup/CMakeFiles/llama-lookup-create.dir/build.make examples/lookup/CMakeFiles/llama-lookup-create.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 76%] Building CXX object examples/lookup/CMakeFiles/llama-lookup-create.dir/lookup-create.cpp.o
cd /opt/llama.cpp/build/examples/lookup && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/lookup/CMakeFiles/llama-lookup-create.dir/lookup-create.cpp.o -MF CMakeFiles/llama-lookup-create.dir/lookup-create.cpp.o.d -o CMakeFiles/llama-lookup-create.dir/lookup-create.cpp.o -c /opt/llama.cpp/examples/lookup/lookup-create.cpp
[ 76%] Linking CXX executable ../bin/test-log
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-log.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-log.dir/test-log.cpp.o" "CMakeFiles/test-log.dir/get-model.cpp.o" -o ../bin/test-log  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 76%] Built target test-log
/usr/bin/gmake  -f examples/lookup/CMakeFiles/llama-lookup-merge.dir/build.make examples/lookup/CMakeFiles/llama-lookup-merge.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/lookup /opt/llama.cpp/build /opt/llama.cpp/build/examples/lookup /opt/llama.cpp/build/examples/lookup/CMakeFiles/llama-lookup-merge.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/lookup/CMakeFiles/llama-lookup-merge.dir/build.make examples/lookup/CMakeFiles/llama-lookup-merge.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 76%] Building CXX object examples/lookup/CMakeFiles/llama-lookup-merge.dir/lookup-merge.cpp.o
cd /opt/llama.cpp/build/examples/lookup && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/lookup/CMakeFiles/llama-lookup-merge.dir/lookup-merge.cpp.o -MF CMakeFiles/llama-lookup-merge.dir/lookup-merge.cpp.o.d -o CMakeFiles/llama-lookup-merge.dir/lookup-merge.cpp.o -c /opt/llama.cpp/examples/lookup/lookup-merge.cpp
[ 76%] Linking CXX executable ../bin/test-rope
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-rope.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-rope.dir/test-rope.cpp.o" "CMakeFiles/test-rope.dir/get-model.cpp.o" -o ../bin/test-rope  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
[ 76%] Linking CXX executable ../bin/test-autorelease
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-autorelease.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-autorelease.dir/test-autorelease.cpp.o" "CMakeFiles/test-autorelease.dir/get-model.cpp.o" -o ../bin/test-autorelease  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 76%] Built target test-rope
/usr/bin/gmake  -f examples/lookup/CMakeFiles/llama-lookup-stats.dir/build.make examples/lookup/CMakeFiles/llama-lookup-stats.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/lookup /opt/llama.cpp/build /opt/llama.cpp/build/examples/lookup /opt/llama.cpp/build/examples/lookup/CMakeFiles/llama-lookup-stats.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/lookup/CMakeFiles/llama-lookup-stats.dir/build.make examples/lookup/CMakeFiles/llama-lookup-stats.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 76%] Building CXX object examples/lookup/CMakeFiles/llama-lookup-stats.dir/lookup-stats.cpp.o
cd /opt/llama.cpp/build/examples/lookup && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/lookup/CMakeFiles/llama-lookup-stats.dir/lookup-stats.cpp.o -MF CMakeFiles/llama-lookup-stats.dir/lookup-stats.cpp.o.d -o CMakeFiles/llama-lookup-stats.dir/lookup-stats.cpp.o -c /opt/llama.cpp/examples/lookup/lookup-stats.cpp
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 76%] Built target test-autorelease
/usr/bin/gmake  -f examples/main/CMakeFiles/llama-cli.dir/build.make examples/main/CMakeFiles/llama-cli.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/main /opt/llama.cpp/build /opt/llama.cpp/build/examples/main /opt/llama.cpp/build/examples/main/CMakeFiles/llama-cli.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/main/CMakeFiles/llama-cli.dir/build.make examples/main/CMakeFiles/llama-cli.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 76%] Linking CXX executable ../bin/test-barrier
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-barrier.dir/link.txt --verbose=1
[ 77%] Building CXX object examples/main/CMakeFiles/llama-cli.dir/main.cpp.o
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-barrier.dir/test-barrier.cpp.o" "CMakeFiles/test-barrier.dir/get-model.cpp.o" -o ../bin/test-barrier  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
cd /opt/llama.cpp/build/examples/main && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/main/CMakeFiles/llama-cli.dir/main.cpp.o -MF CMakeFiles/llama-cli.dir/main.cpp.o.d -o CMakeFiles/llama-cli.dir/main.cpp.o -c /opt/llama.cpp/examples/main/main.cpp
[ 77%] Linking CXX executable ../bin/test-quantize-fns
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-quantize-fns.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o" "CMakeFiles/test-quantize-fns.dir/get-model.cpp.o" -o ../bin/test-quantize-fns  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 77%] Built target test-barrier
/usr/bin/gmake  -f examples/parallel/CMakeFiles/llama-parallel.dir/build.make examples/parallel/CMakeFiles/llama-parallel.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/parallel /opt/llama.cpp/build /opt/llama.cpp/build/examples/parallel /opt/llama.cpp/build/examples/parallel/CMakeFiles/llama-parallel.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/parallel/CMakeFiles/llama-parallel.dir/build.make examples/parallel/CMakeFiles/llama-parallel.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 77%] Building CXX object examples/parallel/CMakeFiles/llama-parallel.dir/parallel.cpp.o
cd /opt/llama.cpp/build/examples/parallel && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/parallel/CMakeFiles/llama-parallel.dir/parallel.cpp.o -MF CMakeFiles/llama-parallel.dir/parallel.cpp.o.d -o CMakeFiles/llama-parallel.dir/parallel.cpp.o -c /opt/llama.cpp/examples/parallel/parallel.cpp
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 77%] Built target test-quantize-fns
/usr/bin/gmake  -f examples/passkey/CMakeFiles/llama-passkey.dir/build.make examples/passkey/CMakeFiles/llama-passkey.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/passkey /opt/llama.cpp/build /opt/llama.cpp/build/examples/passkey /opt/llama.cpp/build/examples/passkey/CMakeFiles/llama-passkey.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/passkey/CMakeFiles/llama-passkey.dir/build.make examples/passkey/CMakeFiles/llama-passkey.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 77%] Building CXX object examples/passkey/CMakeFiles/llama-passkey.dir/passkey.cpp.o
cd /opt/llama.cpp/build/examples/passkey && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/passkey/CMakeFiles/llama-passkey.dir/passkey.cpp.o -MF CMakeFiles/llama-passkey.dir/passkey.cpp.o.d -o CMakeFiles/llama-passkey.dir/passkey.cpp.o -c /opt/llama.cpp/examples/passkey/passkey.cpp
[ 77%] Linking CXX executable ../bin/test-tokenizer-1-spm
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-tokenizer-1-spm.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-tokenizer-1-spm.dir/test-tokenizer-1-spm.cpp.o" -o ../bin/test-tokenizer-1-spm  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
[ 77%] Linking CXX executable ../bin/test-tokenizer-1-bpe
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-tokenizer-1-bpe.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-tokenizer-1-bpe.dir/test-tokenizer-1-bpe.cpp.o" -o ../bin/test-tokenizer-1-bpe  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 77%] Built target test-tokenizer-1-spm
/usr/bin/gmake  -f examples/perplexity/CMakeFiles/llama-perplexity.dir/build.make examples/perplexity/CMakeFiles/llama-perplexity.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/perplexity /opt/llama.cpp/build /opt/llama.cpp/build/examples/perplexity /opt/llama.cpp/build/examples/perplexity/CMakeFiles/llama-perplexity.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/perplexity/CMakeFiles/llama-perplexity.dir/build.make examples/perplexity/CMakeFiles/llama-perplexity.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 78%] Building CXX object examples/perplexity/CMakeFiles/llama-perplexity.dir/perplexity.cpp.o
cd /opt/llama.cpp/build/examples/perplexity && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/perplexity/CMakeFiles/llama-perplexity.dir/perplexity.cpp.o -MF CMakeFiles/llama-perplexity.dir/perplexity.cpp.o.d -o CMakeFiles/llama-perplexity.dir/perplexity.cpp.o -c /opt/llama.cpp/examples/perplexity/perplexity.cpp
[ 78%] Linking CXX executable ../../bin/llama-gbnf-validator
cd /opt/llama.cpp/build/examples/gbnf-validator && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-gbnf-validator.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-gbnf-validator.dir/gbnf-validator.cpp.o" -o ../../bin/llama-gbnf-validator  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 78%] Built target test-tokenizer-1-bpe
/usr/bin/gmake  -f examples/quantize/CMakeFiles/llama-quantize.dir/build.make examples/quantize/CMakeFiles/llama-quantize.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/quantize /opt/llama.cpp/build /opt/llama.cpp/build/examples/quantize /opt/llama.cpp/build/examples/quantize/CMakeFiles/llama-quantize.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/quantize/CMakeFiles/llama-quantize.dir/build.make examples/quantize/CMakeFiles/llama-quantize.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 78%] Building CXX object examples/quantize/CMakeFiles/llama-quantize.dir/quantize.cpp.o
cd /opt/llama.cpp/build/examples/quantize && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/examples/quantize/../../common -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/quantize/CMakeFiles/llama-quantize.dir/quantize.cpp.o -MF CMakeFiles/llama-quantize.dir/quantize.cpp.o.d -o CMakeFiles/llama-quantize.dir/quantize.cpp.o -c /opt/llama.cpp/examples/quantize/quantize.cpp
[ 79%] Linking CXX executable ../../bin/llama-lookup-merge
cd /opt/llama.cpp/build/examples/lookup && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-lookup-merge.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-lookup-merge.dir/lookup-merge.cpp.o" -o ../../bin/llama-lookup-merge  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 79%] Built target llama-gbnf-validator
/usr/bin/gmake  -f examples/retrieval/CMakeFiles/llama-retrieval.dir/build.make examples/retrieval/CMakeFiles/llama-retrieval.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/retrieval /opt/llama.cpp/build /opt/llama.cpp/build/examples/retrieval /opt/llama.cpp/build/examples/retrieval/CMakeFiles/llama-retrieval.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/retrieval/CMakeFiles/llama-retrieval.dir/build.make examples/retrieval/CMakeFiles/llama-retrieval.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 79%] Building CXX object examples/retrieval/CMakeFiles/llama-retrieval.dir/retrieval.cpp.o
cd /opt/llama.cpp/build/examples/retrieval && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/retrieval/CMakeFiles/llama-retrieval.dir/retrieval.cpp.o -MF CMakeFiles/llama-retrieval.dir/retrieval.cpp.o.d -o CMakeFiles/llama-retrieval.dir/retrieval.cpp.o -c /opt/llama.cpp/examples/retrieval/retrieval.cpp
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 79%] Built target llama-lookup-merge
/usr/bin/gmake  -f examples/server/CMakeFiles/llama-server.dir/build.make examples/server/CMakeFiles/llama-server.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 80%] Generating loading.html.hpp
cd /opt/llama.cpp/build/examples/server && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -DINPUT=/opt/llama.cpp/examples/server/public/loading.html -DOUTPUT=/opt/llama.cpp/build/examples/server/loading.html.hpp -P /opt/llama.cpp/scripts/xxd.cmake
[ 80%] Generating index.html.gz.hpp
cd /opt/llama.cpp/build/examples/server && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -DINPUT=/opt/llama.cpp/examples/server/public/index.html.gz -DOUTPUT=/opt/llama.cpp/build/examples/server/index.html.gz.hpp -P /opt/llama.cpp/scripts/xxd.cmake
[ 80%] Linking CXX executable ../bin/test-quantize-perf
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-quantize-perf.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o" "CMakeFiles/test-quantize-perf.dir/get-model.cpp.o" -o ../bin/test-quantize-perf  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 80%] Built target test-quantize-perf
/usr/bin/gmake  -f examples/save-load-state/CMakeFiles/llama-save-load-state.dir/build.make examples/save-load-state/CMakeFiles/llama-save-load-state.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/save-load-state /opt/llama.cpp/build /opt/llama.cpp/build/examples/save-load-state /opt/llama.cpp/build/examples/save-load-state/CMakeFiles/llama-save-load-state.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/save-load-state/CMakeFiles/llama-save-load-state.dir/build.make examples/save-load-state/CMakeFiles/llama-save-load-state.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 81%] Building CXX object examples/save-load-state/CMakeFiles/llama-save-load-state.dir/save-load-state.cpp.o
cd /opt/llama.cpp/build/examples/save-load-state && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/save-load-state/CMakeFiles/llama-save-load-state.dir/save-load-state.cpp.o -MF CMakeFiles/llama-save-load-state.dir/save-load-state.cpp.o.d -o CMakeFiles/llama-save-load-state.dir/save-load-state.cpp.o -c /opt/llama.cpp/examples/save-load-state/save-load-state.cpp
[ 82%] Linking CXX executable ../../bin/llama-gguf-split
cd /opt/llama.cpp/build/examples/gguf-split && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-gguf-split.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-gguf-split.dir/gguf-split.cpp.o" -o ../../bin/llama-gguf-split  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
[ 82%] Linking CXX executable ../../bin/llama-eval-callback
cd /opt/llama.cpp/build/examples/eval-callback && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-eval-callback.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-eval-callback.dir/eval-callback.cpp.o" -o ../../bin/llama-eval-callback  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 82%] Built target llama-gguf-split
/usr/bin/gmake  -f examples/run/CMakeFiles/llama-run.dir/build.make examples/run/CMakeFiles/llama-run.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/run /opt/llama.cpp/build /opt/llama.cpp/build/examples/run /opt/llama.cpp/build/examples/run/CMakeFiles/llama-run.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/run/CMakeFiles/llama-run.dir/build.make examples/run/CMakeFiles/llama-run.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 83%] Building CXX object examples/run/CMakeFiles/llama-run.dir/run.cpp.o
cd /opt/llama.cpp/build/examples/run && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/run/CMakeFiles/llama-run.dir/run.cpp.o -MF CMakeFiles/llama-run.dir/run.cpp.o.d -o CMakeFiles/llama-run.dir/run.cpp.o -c /opt/llama.cpp/examples/run/run.cpp
[ 84%] Linking CXX executable ../../bin/llama-batched-bench
cd /opt/llama.cpp/build/examples/batched-bench && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-batched-bench.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-batched-bench.dir/batched-bench.cpp.o" -o ../../bin/llama-batched-bench  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
[ 84%] Linking CXX executable ../../bin/llama-batched
cd /opt/llama.cpp/build/examples/batched && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-batched.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-batched.dir/batched.cpp.o" -o ../../bin/llama-batched  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
[ 84%] Linking CXX executable ../../bin/llama-lookup-create
cd /opt/llama.cpp/build/examples/lookup && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-lookup-create.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-lookup-create.dir/lookup-create.cpp.o" -o ../../bin/llama-lookup-create  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
[ 84%] Linking CXX executable ../bin/test-sampling
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-sampling.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-sampling.dir/test-sampling.cpp.o" "CMakeFiles/test-sampling.dir/get-model.cpp.o" -o ../bin/test-sampling  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
[ 84%] Linking CXX executable ../bin/test-grammar-parser
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-grammar-parser.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-grammar-parser.dir/test-grammar-parser.cpp.o" "CMakeFiles/test-grammar-parser.dir/get-model.cpp.o" -o ../bin/test-grammar-parser  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
[ 85%] Linking CXX executable ../bin/test-tokenizer-0
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-tokenizer-0.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-tokenizer-0.dir/test-tokenizer-0.cpp.o" -o ../bin/test-tokenizer-0  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
[ 85%] Linking CXX executable ../../bin/llama-gritlm
cd /opt/llama.cpp/build/examples/gritlm && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-gritlm.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-gritlm.dir/gritlm.cpp.o" -o ../../bin/llama-gritlm  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 85%] Built target test-sampling
/usr/bin/gmake  -f examples/speculative/CMakeFiles/llama-speculative.dir/build.make examples/speculative/CMakeFiles/llama-speculative.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/speculative /opt/llama.cpp/build /opt/llama.cpp/build/examples/speculative /opt/llama.cpp/build/examples/speculative/CMakeFiles/llama-speculative.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/speculative/CMakeFiles/llama-speculative.dir/build.make examples/speculative/CMakeFiles/llama-speculative.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 85%] Building CXX object examples/speculative/CMakeFiles/llama-speculative.dir/speculative.cpp.o
cd /opt/llama.cpp/build/examples/speculative && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/speculative/CMakeFiles/llama-speculative.dir/speculative.cpp.o -MF CMakeFiles/llama-speculative.dir/speculative.cpp.o.d -o CMakeFiles/llama-speculative.dir/speculative.cpp.o -c /opt/llama.cpp/examples/speculative/speculative.cpp
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 85%] Built target test-grammar-parser
[ 85%] Building CXX object examples/run/CMakeFiles/llama-run.dir/linenoise.cpp/linenoise.cpp.o
cd /opt/llama.cpp/build/examples/run && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/run/CMakeFiles/llama-run.dir/linenoise.cpp/linenoise.cpp.o -MF CMakeFiles/llama-run.dir/linenoise.cpp/linenoise.cpp.o.d -o CMakeFiles/llama-run.dir/linenoise.cpp/linenoise.cpp.o -c /opt/llama.cpp/examples/run/linenoise.cpp/linenoise.cpp
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 85%] Built target llama-eval-callback
/usr/bin/gmake  -f examples/speculative-simple/CMakeFiles/llama-speculative-simple.dir/build.make examples/speculative-simple/CMakeFiles/llama-speculative-simple.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/speculative-simple /opt/llama.cpp/build /opt/llama.cpp/build/examples/speculative-simple /opt/llama.cpp/build/examples/speculative-simple/CMakeFiles/llama-speculative-simple.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/speculative-simple/CMakeFiles/llama-speculative-simple.dir/build.make examples/speculative-simple/CMakeFiles/llama-speculative-simple.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 85%] Building CXX object examples/speculative-simple/CMakeFiles/llama-speculative-simple.dir/speculative-simple.cpp.o
cd /opt/llama.cpp/build/examples/speculative-simple && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/speculative-simple/CMakeFiles/llama-speculative-simple.dir/speculative-simple.cpp.o -MF CMakeFiles/llama-speculative-simple.dir/speculative-simple.cpp.o.d -o CMakeFiles/llama-speculative-simple.dir/speculative-simple.cpp.o -c /opt/llama.cpp/examples/speculative-simple/speculative-simple.cpp
[ 85%] Linking CXX executable ../../bin/llama-lookup
cd /opt/llama.cpp/build/examples/lookup && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-lookup.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-lookup.dir/lookup.cpp.o" -o ../../bin/llama-lookup  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 85%] Built target test-tokenizer-0
/usr/bin/gmake  -f examples/tokenize/CMakeFiles/llama-tokenize.dir/build.make examples/tokenize/CMakeFiles/llama-tokenize.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/tokenize /opt/llama.cpp/build /opt/llama.cpp/build/examples/tokenize /opt/llama.cpp/build/examples/tokenize/CMakeFiles/llama-tokenize.dir/DependInfo.cmake "--color="
[ 85%] Built target llama-batched-bench
/usr/bin/gmake  -f examples/tts/CMakeFiles/llama-tts.dir/build.make examples/tts/CMakeFiles/llama-tts.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/tts /opt/llama.cpp/build /opt/llama.cpp/build/examples/tts /opt/llama.cpp/build/examples/tts/CMakeFiles/llama-tts.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/tokenize/CMakeFiles/llama-tokenize.dir/build.make examples/tokenize/CMakeFiles/llama-tokenize.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 85%] Linking CXX executable ../bin/test-arg-parser
gmake[2]: Leaving directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-arg-parser.dir/link.txt --verbose=1
/usr/bin/gmake  -f examples/tts/CMakeFiles/llama-tts.dir/build.make examples/tts/CMakeFiles/llama-tts.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 85%] Built target llama-batched
/usr/bin/gmake  -f examples/gen-docs/CMakeFiles/llama-gen-docs.dir/build.make examples/gen-docs/CMakeFiles/llama-gen-docs.dir/depend
[ 86%] Building CXX object examples/tokenize/CMakeFiles/llama-tokenize.dir/tokenize.cpp.o
cd /opt/llama.cpp/build/examples/tokenize && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/tokenize/CMakeFiles/llama-tokenize.dir/tokenize.cpp.o -MF CMakeFiles/llama-tokenize.dir/tokenize.cpp.o.d -o CMakeFiles/llama-tokenize.dir/tokenize.cpp.o -c /opt/llama.cpp/examples/tokenize/tokenize.cpp
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-arg-parser.dir/test-arg-parser.cpp.o" "CMakeFiles/test-arg-parser.dir/get-model.cpp.o" -o ../bin/test-arg-parser  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/gen-docs /opt/llama.cpp/build /opt/llama.cpp/build/examples/gen-docs /opt/llama.cpp/build/examples/gen-docs/CMakeFiles/llama-gen-docs.dir/DependInfo.cmake "--color="
[ 86%] Linking CXX executable ../bin/test-llama-grammar
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-llama-grammar.dir/link.txt --verbose=1
[ 86%] Building CXX object examples/tts/CMakeFiles/llama-tts.dir/tts.cpp.o
cd /opt/llama.cpp/build/examples/tts && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -I/opt/llama.cpp/common/. -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/tts/CMakeFiles/llama-tts.dir/tts.cpp.o -MF CMakeFiles/llama-tts.dir/tts.cpp.o.d -o CMakeFiles/llama-tts.dir/tts.cpp.o -c /opt/llama.cpp/examples/tts/tts.cpp
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/gen-docs/CMakeFiles/llama-gen-docs.dir/build.make examples/gen-docs/CMakeFiles/llama-gen-docs.dir/build
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-llama-grammar.dir/test-llama-grammar.cpp.o" "CMakeFiles/test-llama-grammar.dir/get-model.cpp.o" -o ../bin/test-llama-grammar  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 86%] Built target llama-lookup-create
[ 86%] Building CXX object examples/gen-docs/CMakeFiles/llama-gen-docs.dir/gen-docs.cpp.o
/usr/bin/gmake  -f examples/convert-llama2c-to-ggml/CMakeFiles/llama-convert-llama2c-to-ggml.dir/build.make examples/convert-llama2c-to-ggml/CMakeFiles/llama-convert-llama2c-to-ggml.dir/depend
cd /opt/llama.cpp/build/examples/gen-docs && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/gen-docs/CMakeFiles/llama-gen-docs.dir/gen-docs.cpp.o -MF CMakeFiles/llama-gen-docs.dir/gen-docs.cpp.o.d -o CMakeFiles/llama-gen-docs.dir/gen-docs.cpp.o -c /opt/llama.cpp/examples/gen-docs/gen-docs.cpp
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/convert-llama2c-to-ggml /opt/llama.cpp/build /opt/llama.cpp/build/examples/convert-llama2c-to-ggml /opt/llama.cpp/build/examples/convert-llama2c-to-ggml/CMakeFiles/llama-convert-llama2c-to-ggml.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/convert-llama2c-to-ggml/CMakeFiles/llama-convert-llama2c-to-ggml.dir/build.make examples/convert-llama2c-to-ggml/CMakeFiles/llama-convert-llama2c-to-ggml.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 87%] Building CXX object examples/convert-llama2c-to-ggml/CMakeFiles/llama-convert-llama2c-to-ggml.dir/convert-llama2c-to-ggml.cpp.o
cd /opt/llama.cpp/build/examples/convert-llama2c-to-ggml && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/convert-llama2c-to-ggml/CMakeFiles/llama-convert-llama2c-to-ggml.dir/convert-llama2c-to-ggml.cpp.o -MF CMakeFiles/llama-convert-llama2c-to-ggml.dir/convert-llama2c-to-ggml.cpp.o.d -o CMakeFiles/llama-convert-llama2c-to-ggml.dir/convert-llama2c-to-ggml.cpp.o -c /opt/llama.cpp/examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.cpp
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 87%] Built target llama-gritlm
/usr/bin/gmake  -f examples/cvector-generator/CMakeFiles/llama-cvector-generator.dir/build.make examples/cvector-generator/CMakeFiles/llama-cvector-generator.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/cvector-generator /opt/llama.cpp/build /opt/llama.cpp/build/examples/cvector-generator /opt/llama.cpp/build/examples/cvector-generator/CMakeFiles/llama-cvector-generator.dir/DependInfo.cmake "--color="
[ 87%] Linking CXX executable ../../bin/llama-embedding
cd /opt/llama.cpp/build/examples/embedding && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-embedding.dir/link.txt --verbose=1
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/cvector-generator/CMakeFiles/llama-cvector-generator.dir/build.make examples/cvector-generator/CMakeFiles/llama-cvector-generator.dir/build
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-embedding.dir/embedding.cpp.o" -o ../../bin/llama-embedding  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
[ 87%] Building CXX object examples/cvector-generator/CMakeFiles/llama-cvector-generator.dir/cvector-generator.cpp.o
cd /opt/llama.cpp/build/examples/cvector-generator && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/cvector-generator/CMakeFiles/llama-cvector-generator.dir/cvector-generator.cpp.o -MF CMakeFiles/llama-cvector-generator.dir/cvector-generator.cpp.o.d -o CMakeFiles/llama-cvector-generator.dir/cvector-generator.cpp.o -c /opt/llama.cpp/examples/cvector-generator/cvector-generator.cpp
[ 87%] Built target test-llama-grammar
/usr/bin/gmake  -f examples/export-lora/CMakeFiles/llama-export-lora.dir/build.make examples/export-lora/CMakeFiles/llama-export-lora.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/export-lora /opt/llama.cpp/build /opt/llama.cpp/build/examples/export-lora /opt/llama.cpp/build/examples/export-lora/CMakeFiles/llama-export-lora.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/export-lora/CMakeFiles/llama-export-lora.dir/build.make examples/export-lora/CMakeFiles/llama-export-lora.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 87%] Building CXX object examples/export-lora/CMakeFiles/llama-export-lora.dir/export-lora.cpp.o
cd /opt/llama.cpp/build/examples/export-lora && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/export-lora/CMakeFiles/llama-export-lora.dir/export-lora.cpp.o -MF CMakeFiles/llama-export-lora.dir/export-lora.cpp.o.d -o CMakeFiles/llama-export-lora.dir/export-lora.cpp.o -c /opt/llama.cpp/examples/export-lora/export-lora.cpp
[ 87%] Linking CXX executable ../../bin/llama-lookup-stats
cd /opt/llama.cpp/build/examples/lookup && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-lookup-stats.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-lookup-stats.dir/lookup-stats.cpp.o" -o ../../bin/llama-lookup-stats  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 87%] Built target llama-lookup
/usr/bin/gmake  -f examples/llava/CMakeFiles/llama-llava-cli.dir/build.make examples/llava/CMakeFiles/llama-llava-cli.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/llava /opt/llama.cpp/build /opt/llama.cpp/build/examples/llava /opt/llama.cpp/build/examples/llava/CMakeFiles/llama-llava-cli.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/llava/CMakeFiles/llama-llava-cli.dir/build.make examples/llava/CMakeFiles/llama-llava-cli.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 87%] Building CXX object examples/llava/CMakeFiles/llama-llava-cli.dir/llava-cli.cpp.o
cd /opt/llama.cpp/build/examples/llava && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -I/opt/llama.cpp/examples/llava/. -I/opt/llama.cpp/examples/llava/../.. -I/opt/llama.cpp/examples/llava/../../common -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/llava/CMakeFiles/llama-llava-cli.dir/llava-cli.cpp.o -MF CMakeFiles/llama-llava-cli.dir/llava-cli.cpp.o.d -o CMakeFiles/llama-llava-cli.dir/llava-cli.cpp.o -c /opt/llama.cpp/examples/llava/llava-cli.cpp
[ 88%] Linking CXX executable ../../bin/llama-lookahead
cd /opt/llama.cpp/build/examples/lookahead && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-lookahead.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-lookahead.dir/lookahead.cpp.o" -o ../../bin/llama-lookahead  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 88%] Built target test-arg-parser
/usr/bin/gmake  -f examples/llava/CMakeFiles/llama-minicpmv-cli.dir/build.make examples/llava/CMakeFiles/llama-minicpmv-cli.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/llava /opt/llama.cpp/build /opt/llama.cpp/build/examples/llava /opt/llama.cpp/build/examples/llava/CMakeFiles/llama-minicpmv-cli.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/llava/CMakeFiles/llama-minicpmv-cli.dir/build.make examples/llava/CMakeFiles/llama-minicpmv-cli.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 89%] Building CXX object examples/llava/CMakeFiles/llama-minicpmv-cli.dir/minicpmv-cli.cpp.o
cd /opt/llama.cpp/build/examples/llava && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -I/opt/llama.cpp/examples/llava/. -I/opt/llama.cpp/examples/llava/../.. -I/opt/llama.cpp/examples/llava/../../common -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/llava/CMakeFiles/llama-minicpmv-cli.dir/minicpmv-cli.cpp.o -MF CMakeFiles/llama-minicpmv-cli.dir/minicpmv-cli.cpp.o.d -o CMakeFiles/llama-minicpmv-cli.dir/minicpmv-cli.cpp.o -c /opt/llama.cpp/examples/llava/minicpmv-cli.cpp
/opt/llama.cpp/examples/perplexity/perplexity.cpp: In lambda function:
/opt/llama.cpp/examples/perplexity/perplexity.cpp:1736:41: note: parameter passing for argument of type std::pair<double, double> when C++17 is enabled changed to match C++14 in GCC 10.1
 1736 |             return std::make_pair(0., 0.);
      |                                         ^
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 89%] Built target llama-embedding
/usr/bin/gmake  -f examples/llava/CMakeFiles/llama-qwen2vl-cli.dir/build.make examples/llava/CMakeFiles/llama-qwen2vl-cli.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/llava /opt/llama.cpp/build /opt/llama.cpp/build/examples/llava /opt/llama.cpp/build/examples/llava/CMakeFiles/llama-qwen2vl-cli.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/llava/CMakeFiles/llama-qwen2vl-cli.dir/build.make examples/llava/CMakeFiles/llama-qwen2vl-cli.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 89%] Building CXX object examples/llava/CMakeFiles/llama-qwen2vl-cli.dir/qwen2vl-cli.cpp.o
cd /opt/llama.cpp/build/examples/llava && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -I/opt/llama.cpp/examples/llava/. -I/opt/llama.cpp/examples/llava/../.. -I/opt/llama.cpp/examples/llava/../../common -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/llava/CMakeFiles/llama-qwen2vl-cli.dir/qwen2vl-cli.cpp.o -MF CMakeFiles/llama-qwen2vl-cli.dir/qwen2vl-cli.cpp.o.d -o CMakeFiles/llama-qwen2vl-cli.dir/qwen2vl-cli.cpp.o -c /opt/llama.cpp/examples/llava/qwen2vl-cli.cpp
[ 90%] Linking CXX executable ../../bin/llama-infill
cd /opt/llama.cpp/build/examples/infill && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-infill.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-infill.dir/infill.cpp.o" -o ../../bin/llama-infill  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 90%] Built target llama-lookup-stats
/usr/bin/gmake  -f examples/llava/CMakeFiles/llama-gemma3-cli.dir/build.make examples/llava/CMakeFiles/llama-gemma3-cli.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/llava /opt/llama.cpp/build /opt/llama.cpp/build/examples/llava /opt/llama.cpp/build/examples/llava/CMakeFiles/llama-gemma3-cli.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/llava/CMakeFiles/llama-gemma3-cli.dir/build.make examples/llava/CMakeFiles/llama-gemma3-cli.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 91%] Building CXX object examples/llava/CMakeFiles/llama-gemma3-cli.dir/gemma3-cli.cpp.o
cd /opt/llama.cpp/build/examples/llava && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -I/opt/llama.cpp/examples/llava/. -I/opt/llama.cpp/examples/llava/../.. -I/opt/llama.cpp/examples/llava/../../common -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/llava/CMakeFiles/llama-gemma3-cli.dir/gemma3-cli.cpp.o -MF CMakeFiles/llama-gemma3-cli.dir/gemma3-cli.cpp.o.d -o CMakeFiles/llama-gemma3-cli.dir/gemma3-cli.cpp.o -c /opt/llama.cpp/examples/llava/gemma3-cli.cpp
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 91%] Built target llama-lookahead
/usr/bin/gmake  -f examples/llava/CMakeFiles/llama-llava-clip-quantize-cli.dir/build.make examples/llava/CMakeFiles/llama-llava-clip-quantize-cli.dir/depend
[ 91%] Linking CXX executable ../../bin/llama-passkey
cd /opt/llama.cpp/build/examples/passkey && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-passkey.dir/link.txt --verbose=1
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/llava /opt/llama.cpp/build /opt/llama.cpp/build/examples/llava /opt/llama.cpp/build/examples/llava/CMakeFiles/llama-llava-clip-quantize-cli.dir/DependInfo.cmake "--color="
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-passkey.dir/passkey.cpp.o" -o ../../bin/llama-passkey  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/llava/CMakeFiles/llama-llava-clip-quantize-cli.dir/build.make examples/llava/CMakeFiles/llama-llava-clip-quantize-cli.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 92%] Building CXX object examples/llava/CMakeFiles/llama-llava-clip-quantize-cli.dir/clip-quantize-cli.cpp.o
cd /opt/llama.cpp/build/examples/llava && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -I/opt/llama.cpp/examples/llava/. -I/opt/llama.cpp/examples/llava/../.. -I/opt/llama.cpp/examples/llava/../../common -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/llava/CMakeFiles/llama-llava-clip-quantize-cli.dir/clip-quantize-cli.cpp.o -MF CMakeFiles/llama-llava-clip-quantize-cli.dir/clip-quantize-cli.cpp.o.d -o CMakeFiles/llama-llava-clip-quantize-cli.dir/clip-quantize-cli.cpp.o -c /opt/llama.cpp/examples/llava/clip-quantize-cli.cpp
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 92%] Built target llama-infill
/usr/bin/gmake  -f pocs/vdot/CMakeFiles/llama-vdot.dir/build.make pocs/vdot/CMakeFiles/llama-vdot.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/pocs/vdot /opt/llama.cpp/build /opt/llama.cpp/build/pocs/vdot /opt/llama.cpp/build/pocs/vdot/CMakeFiles/llama-vdot.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f pocs/vdot/CMakeFiles/llama-vdot.dir/build.make pocs/vdot/CMakeFiles/llama-vdot.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 92%] Building CXX object pocs/vdot/CMakeFiles/llama-vdot.dir/vdot.cpp.o
cd /opt/llama.cpp/build/pocs/vdot && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/pocs -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -MD -MT pocs/vdot/CMakeFiles/llama-vdot.dir/vdot.cpp.o -MF CMakeFiles/llama-vdot.dir/vdot.cpp.o.d -o CMakeFiles/llama-vdot.dir/vdot.cpp.o -c /opt/llama.cpp/pocs/vdot/vdot.cpp
[ 92%] Linking CXX executable ../bin/test-chat-template
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-chat-template.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-chat-template.dir/test-chat-template.cpp.o" "CMakeFiles/test-chat-template.dir/get-model.cpp.o" -o ../bin/test-chat-template  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 92%] Built target llama-passkey
/usr/bin/gmake  -f pocs/vdot/CMakeFiles/llama-q8dot.dir/build.make pocs/vdot/CMakeFiles/llama-q8dot.dir/depend
gmake[2]: Entering directory '/opt/llama.cpp/build'
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/pocs/vdot /opt/llama.cpp/build /opt/llama.cpp/build/pocs/vdot /opt/llama.cpp/build/pocs/vdot/CMakeFiles/llama-q8dot.dir/DependInfo.cmake "--color="
[ 93%] Linking CXX executable ../../bin/llama-parallel
cd /opt/llama.cpp/build/examples/parallel && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-parallel.dir/link.txt --verbose=1
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f pocs/vdot/CMakeFiles/llama-q8dot.dir/build.make pocs/vdot/CMakeFiles/llama-q8dot.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-parallel.dir/parallel.cpp.o" -o ../../bin/llama-parallel  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
[ 93%] Building CXX object pocs/vdot/CMakeFiles/llama-q8dot.dir/q8dot.cpp.o
cd /opt/llama.cpp/build/pocs/vdot && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/pocs -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -MD -MT pocs/vdot/CMakeFiles/llama-q8dot.dir/q8dot.cpp.o -MF CMakeFiles/llama-q8dot.dir/q8dot.cpp.o.d -o CMakeFiles/llama-q8dot.dir/q8dot.cpp.o -c /opt/llama.cpp/pocs/vdot/q8dot.cpp
[ 93%] Linking CXX executable ../bin/test-gguf
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-gguf.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-gguf.dir/test-gguf.cpp.o" "CMakeFiles/test-gguf.dir/get-model.cpp.o" -o ../bin/test-gguf  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
[ 93%] Linking CXX executable ../../bin/llama-tokenize
cd /opt/llama.cpp/build/examples/tokenize && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-tokenize.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-tokenize.dir/tokenize.cpp.o" -o ../../bin/llama-tokenize  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 93%] Built target test-gguf
[ 93%] Linking CXX executable ../../bin/llama-save-load-state
cd /opt/llama.cpp/build/examples/save-load-state && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-save-load-state.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-save-load-state.dir/save-load-state.cpp.o" -o ../../bin/llama-save-load-state  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 93%] Built target test-chat-template
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 93%] Built target llama-parallel
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 93%] Built target llama-tokenize
[ 93%] Linking CXX executable ../../bin/llama-quantize
cd /opt/llama.cpp/build/examples/quantize && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-quantize.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-quantize.dir/quantize.cpp.o" -o ../../bin/llama-quantize  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
[ 93%] Linking CXX executable ../../bin/llama-llava-clip-quantize-cli
cd /opt/llama.cpp/build/examples/llava && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-llava-clip-quantize-cli.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-llava-clip-quantize-cli.dir/clip-quantize-cli.cpp.o" CMakeFiles/llava.dir/llava.cpp.o CMakeFiles/llava.dir/clip.cpp.o -o ../../bin/llama-llava-clip-quantize-cli  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 93%] Built target llama-save-load-state
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 93%] Built target llama-llava-clip-quantize-cli
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 93%] Built target llama-quantize
[ 93%] Linking CXX executable ../../bin/llama-speculative-simple
cd /opt/llama.cpp/build/examples/speculative-simple && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-speculative-simple.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-speculative-simple.dir/speculative-simple.cpp.o" -o ../../bin/llama-speculative-simple  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
[ 94%] Linking CXX executable ../../bin/llama-gen-docs
cd /opt/llama.cpp/build/examples/gen-docs && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-gen-docs.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-gen-docs.dir/gen-docs.cpp.o" -o ../../bin/llama-gen-docs  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
[ 95%] Linking CXX executable ../../bin/llama-q8dot
cd /opt/llama.cpp/build/pocs/vdot && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-q8dot.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-q8dot.dir/q8dot.cpp.o" -o ../../bin/llama-q8dot  -Wl,-rpath,/opt/llama.cpp/build/bin ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
[ 95%] Linking CXX executable ../../bin/llama-vdot
cd /opt/llama.cpp/build/pocs/vdot && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-vdot.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-vdot.dir/vdot.cpp.o" -o ../../bin/llama-vdot  -Wl,-rpath,/opt/llama.cpp/build/bin ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 95%] Built target llama-speculative-simple
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 95%] Built target llama-q8dot
gmake[2]: Leaving directory '/opt/llama.cpp/build'
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 95%] Built target llama-gen-docs
[ 95%] Built target llama-vdot
[ 95%] Linking CXX executable ../../bin/llama-retrieval
cd /opt/llama.cpp/build/examples/retrieval && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-retrieval.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-retrieval.dir/retrieval.cpp.o" -o ../../bin/llama-retrieval  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
[ 95%] Linking CXX executable ../../bin/llama-cli
cd /opt/llama.cpp/build/examples/main && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-cli.dir/link.txt --verbose=1
[ 95%] Linking CXX executable ../../bin/llama-llava-cli
cd /opt/llama.cpp/build/examples/llava && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-llava-cli.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-cli.dir/main.cpp.o" -o ../../bin/llama-cli  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-llava-cli.dir/llava-cli.cpp.o" CMakeFiles/llava.dir/llava.cpp.o CMakeFiles/llava.dir/clip.cpp.o -o ../../bin/llama-llava-cli  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
[ 95%] Linking CXX executable ../../bin/llama-minicpmv-cli
cd /opt/llama.cpp/build/examples/llava && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-minicpmv-cli.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-minicpmv-cli.dir/minicpmv-cli.cpp.o" CMakeFiles/llava.dir/llava.cpp.o CMakeFiles/llava.dir/clip.cpp.o -o ../../bin/llama-minicpmv-cli  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
cd /opt/llama.cpp/build && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_depends "Unix Makefiles" /opt/llama.cpp /opt/llama.cpp/examples/server /opt/llama.cpp/build /opt/llama.cpp/build/examples/server /opt/llama.cpp/build/examples/server/CMakeFiles/llama-server.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/opt/llama.cpp/build'
/usr/bin/gmake  -f examples/server/CMakeFiles/llama-server.dir/build.make examples/server/CMakeFiles/llama-server.dir/build
gmake[2]: Entering directory '/opt/llama.cpp/build'
[ 95%] Building CXX object examples/server/CMakeFiles/llama-server.dir/server.cpp.o
cd /opt/llama.cpp/build/examples/server && /usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/opt/llama.cpp/examples -I/opt/llama.cpp/examples/server -I/opt/llama.cpp/build/examples/server -I/opt/llama.cpp -I/opt/llama.cpp/common/. -I/opt/llama.cpp/src/. -I/opt/llama.cpp/src/../include -I/opt/llama.cpp/src/../common -I/opt/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -MD -MT examples/server/CMakeFiles/llama-server.dir/server.cpp.o -MF CMakeFiles/llama-server.dir/server.cpp.o.d -o CMakeFiles/llama-server.dir/server.cpp.o -c /opt/llama.cpp/examples/server/server.cpp
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 95%] Linking CXX executable ../../bin/llama-convert-llama2c-to-ggml
cd /opt/llama.cpp/build/examples/convert-llama2c-to-ggml && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-convert-llama2c-to-ggml.dir/link.txt --verbose=1
[ 95%] Built target llama-retrieval
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-convert-llama2c-to-ggml.dir/convert-llama2c-to-ggml.cpp.o" -o ../../bin/llama-convert-llama2c-to-ggml  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
[ 95%] Linking CXX executable ../../bin/llama-gemma3-cli
cd /opt/llama.cpp/build/examples/llava && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-gemma3-cli.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-gemma3-cli.dir/gemma3-cli.cpp.o" CMakeFiles/llava.dir/llava.cpp.o CMakeFiles/llava.dir/clip.cpp.o -o ../../bin/llama-gemma3-cli  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 95%] Built target llama-cli
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 95%] Built target llama-llava-cli
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 95%] Built target llama-minicpmv-cli
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 95%] Built target llama-convert-llama2c-to-ggml
[ 96%] Linking CXX executable ../../bin/llama-qwen2vl-cli
cd /opt/llama.cpp/build/examples/llava && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-qwen2vl-cli.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-qwen2vl-cli.dir/qwen2vl-cli.cpp.o" CMakeFiles/llava.dir/llava.cpp.o CMakeFiles/llava.dir/clip.cpp.o -o ../../bin/llama-qwen2vl-cli  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
[ 96%] Linking CXX executable ../../bin/llama-imatrix
cd /opt/llama.cpp/build/examples/imatrix && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-imatrix.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-imatrix.dir/imatrix.cpp.o" -o ../../bin/llama-imatrix  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 96%] Built target llama-gemma3-cli
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 96%] Built target llama-qwen2vl-cli
[ 97%] Linking CXX executable ../../bin/llama-export-lora
cd /opt/llama.cpp/build/examples/export-lora && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-export-lora.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-export-lora.dir/export-lora.cpp.o" -o ../../bin/llama-export-lora  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 97%] Built target llama-imatrix
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 97%] Built target llama-export-lora
[ 98%] Linking CXX executable ../../bin/llama-speculative
cd /opt/llama.cpp/build/examples/speculative && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-speculative.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-speculative.dir/speculative.cpp.o" -o ../../bin/llama-speculative  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
[ 99%] Linking CXX executable ../../bin/llama-cvector-generator
cd /opt/llama.cpp/build/examples/cvector-generator && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-cvector-generator.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-cvector-generator.dir/cvector-generator.cpp.o" -o ../../bin/llama-cvector-generator  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 99%] Built target llama-speculative
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 99%] Built target llama-cvector-generator
[ 99%] Linking CXX executable ../../bin/llama-perplexity
cd /opt/llama.cpp/build/examples/perplexity && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-perplexity.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-perplexity.dir/perplexity.cpp.o" -o ../../bin/llama-perplexity  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 99%] Built target llama-perplexity
[ 99%] Linking CXX executable ../bin/test-grammar-integration
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-grammar-integration.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-grammar-integration.dir/test-grammar-integration.cpp.o" "CMakeFiles/test-grammar-integration.dir/get-model.cpp.o" -o ../bin/test-grammar-integration  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 99%] Built target test-grammar-integration
[ 99%] Linking CXX executable ../../bin/llama-run
cd /opt/llama.cpp/build/examples/run && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-run.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-run.dir/run.cpp.o" "CMakeFiles/llama-run.dir/linenoise.cpp/linenoise.cpp.o" -o ../../bin/llama-run  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 99%] Built target llama-run
[ 99%] Linking CXX executable ../bin/test-json-schema-to-grammar
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-json-schema-to-grammar.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-json-schema-to-grammar.dir/test-json-schema-to-grammar.cpp.o" "CMakeFiles/test-json-schema-to-grammar.dir/get-model.cpp.o" -o ../bin/test-json-schema-to-grammar  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 99%] Built target test-json-schema-to-grammar
[ 99%] Linking CXX executable ../../bin/llama-bench
cd /opt/llama.cpp/build/examples/llama-bench && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-bench.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-bench.dir/llama-bench.cpp.o" -o ../../bin/llama-bench  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[ 99%] Built target llama-bench
[ 99%] Linking CXX executable ../bin/test-chat
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-chat.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-chat.dir/test-chat.cpp.o" "CMakeFiles/test-chat.dir/get-model.cpp.o" -o ../bin/test-chat  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
[100%] Linking CXX executable ../../bin/llama-tts
cd /opt/llama.cpp/build/examples/tts && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-tts.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-tts.dir/tts.cpp.o" -o ../../bin/llama-tts  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so /usr/lib/aarch64-linux-gnu/libcurl.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[100%] Built target test-chat
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[100%] Built target llama-tts
[100%] Linking CXX executable ../bin/test-backend-ops
cd /opt/llama.cpp/build/tests && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/test-backend-ops.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o" "CMakeFiles/test-backend-ops.dir/get-model.cpp.o" -o ../bin/test-backend-ops  -Wl,-rpath,/opt/llama.cpp/build/bin: ../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../bin/libllama.so ../bin/libggml.so ../bin/libggml-cpu.so ../bin/libggml-cuda.so ../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[100%] Built target test-backend-ops
[100%] Linking CXX executable ../../bin/llama-server
cd /opt/llama.cpp/build/examples/server && /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/llama-server.dir/link.txt --verbose=1
/usr/bin/c++ -O3 -DNDEBUG "CMakeFiles/llama-server.dir/server.cpp.o" -o ../../bin/llama-server  -Wl,-rpath,/opt/llama.cpp/build/bin: ../../common/libcommon.a /usr/lib/aarch64-linux-gnu/libcurl.so ../../bin/libllama.so ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-cuda.so ../../bin/libggml-base.so /usr/local/cuda/targets/sbsa-linux/lib/stubs/libcuda.so
gmake[2]: Leaving directory '/opt/llama.cpp/build'
[100%] Built target llama-server
gmake[1]: Leaving directory '/opt/llama.cpp/build'
/usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_progress_start /opt/llama.cpp/build/CMakeFiles 0

+ cmake --install .
-- Install configuration: "Release"
-- Installing: /usr/local/lib/libggml-cpu.so
-- Set non-toolchain portion of runtime path of "/usr/local/lib/libggml-cpu.so" to ""
-- Installing: /usr/local/lib/libggml-cuda.so
-- Set non-toolchain portion of runtime path of "/usr/local/lib/libggml-cuda.so" to ""
-- Installing: /usr/local/lib/libggml.so
-- Set non-toolchain portion of runtime path of "/usr/local/lib/libggml.so" to ""
-- Installing: /usr/local/include/ggml.h
-- Installing: /usr/local/include/ggml-cpu.h
-- Installing: /usr/local/include/ggml-alloc.h
-- Installing: /usr/local/include/ggml-backend.h
-- Installing: /usr/local/include/ggml-blas.h
-- Installing: /usr/local/include/ggml-cann.h
-- Installing: /usr/local/include/ggml-cpp.h
-- Installing: /usr/local/include/ggml-cuda.h
-- Installing: /usr/local/include/ggml-kompute.h
-- Installing: /usr/local/include/ggml-opt.h
-- Installing: /usr/local/include/ggml-metal.h
-- Installing: /usr/local/include/ggml-rpc.h
-- Installing: /usr/local/include/ggml-sycl.h
-- Installing: /usr/local/include/ggml-vulkan.h
-- Installing: /usr/local/include/gguf.h
-- Installing: /usr/local/lib/libggml-base.so
-- Installing: /usr/local/lib/cmake/ggml/ggml-config.cmake
-- Installing: /usr/local/lib/cmake/ggml/ggml-version.cmake
-- Installing: /usr/local/bin/test-tokenizer-0
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-tokenizer-0" to ""
-- Installing: /usr/local/bin/test-sampling
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-sampling" to ""
-- Installing: /usr/local/bin/test-grammar-parser
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-grammar-parser" to ""
-- Installing: /usr/local/bin/test-grammar-integration
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-grammar-integration" to ""
-- Installing: /usr/local/bin/test-llama-grammar
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-llama-grammar" to ""
-- Installing: /usr/local/bin/test-chat
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-chat" to ""
-- Installing: /usr/local/bin/test-json-schema-to-grammar
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-json-schema-to-grammar" to ""
-- Installing: /usr/local/bin/test-tokenizer-1-bpe
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-tokenizer-1-bpe" to ""
-- Installing: /usr/local/bin/test-tokenizer-1-spm
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-tokenizer-1-spm" to ""
-- Installing: /usr/local/bin/test-log
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-log" to ""
-- Installing: /usr/local/bin/test-arg-parser
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-arg-parser" to ""
-- Installing: /usr/local/bin/test-chat-template
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-chat-template" to ""
-- Installing: /usr/local/bin/test-gguf
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-gguf" to ""
-- Installing: /usr/local/bin/test-backend-ops
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-backend-ops" to ""
-- Installing: /usr/local/bin/test-model-load-cancel
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-model-load-cancel" to ""
-- Installing: /usr/local/bin/test-autorelease
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-autorelease" to ""
-- Installing: /usr/local/bin/test-barrier
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-barrier" to ""
-- Installing: /usr/local/bin/test-quantize-fns
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-quantize-fns" to ""
-- Installing: /usr/local/bin/test-quantize-perf
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-quantize-perf" to ""
-- Installing: /usr/local/bin/test-rope
-- Set non-toolchain portion of runtime path of "/usr/local/bin/test-rope" to ""
-- Installing: /usr/local/bin/llama-batched-bench
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-batched-bench" to ""
-- Installing: /usr/local/bin/llama-batched
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-batched" to ""
-- Installing: /usr/local/bin/llama-embedding
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-embedding" to ""
-- Installing: /usr/local/bin/llama-eval-callback
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-eval-callback" to ""
-- Installing: /usr/local/bin/llama-gbnf-validator
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-gbnf-validator" to ""
-- Installing: /usr/local/bin/llama-gguf-hash
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-gguf-hash" to ""
-- Installing: /usr/local/bin/llama-gguf-split
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-gguf-split" to ""
-- Installing: /usr/local/bin/llama-gguf
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-gguf" to ""
-- Installing: /usr/local/bin/llama-gritlm
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-gritlm" to ""
-- Installing: /usr/local/bin/llama-imatrix
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-imatrix" to ""
-- Installing: /usr/local/bin/llama-infill
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-infill" to ""
-- Installing: /usr/local/bin/llama-bench
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-bench" to ""
-- Installing: /usr/local/bin/llama-lookahead
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-lookahead" to ""
-- Installing: /usr/local/bin/llama-lookup
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-lookup" to ""
-- Installing: /usr/local/bin/llama-lookup-create
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-lookup-create" to ""
-- Installing: /usr/local/bin/llama-lookup-merge
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-lookup-merge" to ""
-- Installing: /usr/local/bin/llama-lookup-stats
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-lookup-stats" to ""
-- Installing: /usr/local/bin/llama-cli
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-cli" to ""
-- Installing: /usr/local/bin/llama-parallel
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-parallel" to ""
-- Installing: /usr/local/bin/llama-passkey
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-passkey" to ""
-- Installing: /usr/local/bin/llama-perplexity
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-perplexity" to ""
-- Installing: /usr/local/bin/llama-quantize
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-quantize" to ""
-- Installing: /usr/local/bin/llama-retrieval
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-retrieval" to ""
-- Installing: /usr/local/bin/llama-server
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-server" to ""
-- Installing: /usr/local/bin/llama-save-load-state
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-save-load-state" to ""
-- Installing: /usr/local/bin/llama-run
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-run" to ""
-- Installing: /usr/local/bin/llama-simple
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-simple" to ""
-- Installing: /usr/local/bin/llama-simple-chat
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-simple-chat" to ""
-- Installing: /usr/local/bin/llama-speculative
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-speculative" to ""
-- Installing: /usr/local/bin/llama-speculative-simple
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-speculative-simple" to ""
-- Installing: /usr/local/bin/llama-tokenize
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-tokenize" to ""
-- Installing: /usr/local/bin/llama-tts
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-tts" to ""
-- Installing: /usr/local/bin/llama-gen-docs
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-gen-docs" to ""
-- Installing: /usr/local/bin/llama-convert-llama2c-to-ggml
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-convert-llama2c-to-ggml" to ""
-- Installing: /usr/local/bin/llama-cvector-generator
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-cvector-generator" to ""
-- Installing: /usr/local/bin/llama-export-lora
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-export-lora" to ""
-- Installing: /usr/local/bin/llama-quantize-stats
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-quantize-stats" to ""
-- Installing: /usr/local/lib/libllava_shared.so
-- Set non-toolchain portion of runtime path of "/usr/local/lib/libllava_shared.so" to ""
-- Installing: /usr/local/bin/llama-llava-cli
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-llava-cli" to ""
-- Installing: /usr/local/bin/llama-minicpmv-cli
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-minicpmv-cli" to ""
-- Installing: /usr/local/bin/llama-qwen2vl-cli
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-qwen2vl-cli" to ""
-- Installing: /usr/local/bin/llama-gemma3-cli
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-gemma3-cli" to ""
-- Installing: /usr/local/bin/llama-llava-clip-quantize-cli
-- Set non-toolchain portion of runtime path of "/usr/local/bin/llama-llava-clip-quantize-cli" to ""
-- Installing: /usr/local/lib/libllama.so
-- Set non-toolchain portion of runtime path of "/usr/local/lib/libllama.so" to ""
-- Installing: /usr/local/include/llama.h
-- Installing: /usr/local/include/llama-cpp.h
-- Installing: /usr/local/lib/cmake/llama/llama-config.cmake
-- Installing: /usr/local/lib/cmake/llama/llama-version.cmake
-- Installing: /usr/local/bin/convert_hf_to_gguf.py
-- Installing: /usr/local/lib/pkgconfig/llama.pc
+ cd /opt
+ rm -rf llama.cpp
INFO:    Adding environment to container
INFO:    Creating SIF file...
INFO:    Build complete: llama.cpp2.sif
